(this.webpackJsonpgamelab=this.webpackJsonpgamelab||[]).push([[0],{170:function(e,t,n){},171:function(e,t,n){"use strict";n.r(t);var s=n(0),a=n(1),i=n.n(a),o=n(68),r=n.n(o),l=(n(53),n(75),n(76),n(11)),c=n(7),h=n(25),d=n(26),m=n(29),u=n(28),f=n(15),p=n(16),b=n(27),g=function(){return Object(s.jsx)(f.b,Object(p.a)({style:{backgroundColor:"#000000",color:"#CCFF00",padding:"1em",fontFamily:"AudioWide"},children:null},"children",Object(s.jsx)("div",{className:"row justify-content-center h-100 align-items-center",children:Object(s.jsx)(b.a.h1,{className:"unselectable",style:{fontSize:"12vw"},initial:{scale:0,opacity:0},animate:{scale:1,opacity:1},transition:{duration:1},children:"GAMELAB"})})))},w=function(e){return Object(s.jsx)("div",{className:"card m-1",children:Object(s.jsxs)("div",{className:"card-body py-1 row",children:[Object(s.jsx)("img",{alt:"img",src:"/assets/thumbnails/"+e.image,width:"50px",style:{borderRadius:"50px"}}),Object(s.jsx)("span",{className:"ml-lg-2 ml-xl-3",children:e.name})]})})},y=function(){return Object(s.jsx)(f.b,Object(p.a)({style:{backgroundColor:"#FFFFFF",padding:"1em"},children:null},"children",Object(s.jsxs)("div",{className:"mx-5",children:[Object(s.jsx)("div",{className:"row justify-content-center",children:Object(s.jsx)("h1",{style:{fontFamily:"AudioWide",fontSize:"4rem"},children:"GAMELAB"})}),Object(s.jsx)("div",{className:"row justify-content-center overflow-auto",children:Object(s.jsxs)("p",{className:"lead",style:{fontFamily:"Oswald"},children:["With ",Object(s.jsx)("span",{style:{color:"red"},children:"\u2764"})," from Team Captain's Mistress"]})}),Object(s.jsx)("hr",{}),Object(s.jsxs)("div",{className:"row",style:{fontFamily:"Oswald"},children:[Object(s.jsxs)("div",{className:"d-flex-column col-12 col-lg-5 ml-lg-2",children:[Object(s.jsxs)("h3",{className:"text-center",children:["About",Object(s.jsx)("br",{})," GAMELAB"]}),Object(s.jsxs)("p",{className:"mt-4 text-center mx-3",style:{fontSize:"1.2rem"},children:["GAMELAB is our final project for the ",Object(s.jsx)("strong",{children:"Algorithms Analysis and Design"})," course in Monsoon 2020. The idea is to break down some simple skill-based games and to identify and analyze optimal solutions for them. We analyzed 4 relatively simple skill-based games to gather the required know-how and experience to be able to tackle the final target: ",Object(s.jsx)("strong",{children:"Scotland Yard"}),". This site is a culmination of all our findings for each of the games that we have analyzed."]})]}),Object(s.jsxs)("div",{className:"d-flex-column d-none d-lg-block col-lg-6",style:{borderLeft:"2px solid rgba(0, 0, 0, 0.05)"},children:[Object(s.jsxs)("h3",{className:"text-center",children:["About",Object(s.jsx)("br",{})," Team Captain's Mistress"]}),Object(s.jsxs)("p",{className:"mt-4 text-center mx-3",style:{fontSize:"1.2rem"},children:[Object(s.jsx)("strong",{children:"Captain's Mistress"})," is a team of 7 super-stressed, caffine-filled 2nd year students from IIIT Hyderabad."]}),Object(s.jsxs)("div",{className:"row mt-4 mx-2 justify-content-center",children:[Object(s.jsxs)("div",{className:"d-flex-column col-5 col-xl-4",children:[Object(s.jsx)(w,{name:"Arihanth T.",image:"arihanth.jpeg"}),Object(s.jsx)(w,{name:"Mehul Mathur",image:"mehul.jpeg"}),Object(s.jsx)(w,{name:"Ritvik Kalra",image:"ritvik.jpg"}),Object(s.jsx)(w,{name:"Sidharth Giri",image:"sidharth.jpg"})]}),Object(s.jsx)("div",{className:"col-1"}),Object(s.jsxs)("div",{className:"d-flex-column col-5 col-xl-4",children:[Object(s.jsx)(w,{name:"Dhruv Kapur",image:"dhruv.png"}),Object(s.jsx)(w,{name:"Pooja Desur",image:"pooja.jpg"}),Object(s.jsx)(w,{name:"Shivansh S.",image:"shivansh.jpg"})]})]})]})]})]})))},j=function(){return Object(s.jsx)(f.b,Object(p.a)({className:"d-block d-lg-none",style:{backgroundColor:"#FFFFFF",padding:"1em"},children:null},"children",Object(s.jsxs)("div",{className:"container mt-5",style:{fontFamily:"Oswald"},children:[Object(s.jsx)("h1",{className:"text-center",style:{fontFamily:"AudioWide"},children:" TEAM CAPTAIN'S MISTRESS"}),Object(s.jsxs)("p",{className:"my-5 text-center mx-3",style:{fontSize:"1.2rem"},children:[Object(s.jsx)("strong",{children:"Captain's Mistress"})," is a team of 7 super-stressed, caffine-filled 2nd year students from IIIT Hyderabad."]}),Object(s.jsxs)("div",{className:"row mt-4 justify-content-center",children:[Object(s.jsxs)("div",{className:"d-flex-column col-6",children:[Object(s.jsx)(w,{name:"Arihanth T.",image:"arihanth.jpeg"}),Object(s.jsx)(w,{name:"Mehul Mathur",image:"mehul.jpeg"}),Object(s.jsx)(w,{name:"Ritvik Kalra",image:"ritvik.jpg"}),Object(s.jsx)(w,{name:"Sidharth Giri",image:"sidharth.jpg"})]}),Object(s.jsxs)("div",{className:"d-flex-column col-6",children:[Object(s.jsx)(w,{name:"Dhruv Kapur",image:"dhruv.png"}),Object(s.jsx)(w,{name:"Pooja Desur",image:"pooja.jpg"}),Object(s.jsx)(w,{name:"Shivansh S.",image:"shivansh.jpg"})]})]})]})))},v=function(e){return Object(s.jsx)("div",{className:"card mb-3 col-8 mx-4",children:Object(s.jsxs)("div",{className:"row no-gutters",children:[Object(s.jsx)("div",{className:"col-md-4",children:Object(s.jsx)("img",{src:"/assets/thumbnails/"+e.image,className:"card-img",alt:"..."})}),Object(s.jsx)("div",{className:"col-md-8",children:Object(s.jsxs)("div",{className:"card-body",children:[Object(s.jsx)("h5",{className:"card-title",children:e.name}),Object(s.jsx)("p",{className:"card-text d-none d-md-block",children:e.desc}),Object(s.jsx)(l.b,{to:e.link,className:"btn btn-outline-success",children:"Read More"})]})})]})})},x=function(){return Object(s.jsx)(f.b,Object(p.a)({style:{backgroundColor:"#FFFFFF",padding:"1em",fontFamily:"Oswald"},children:null},"children",Object(s.jsxs)("div",{className:"container",children:[Object(s.jsx)("div",{className:"row my-1 my-md-5",children:Object(s.jsx)("h1",{className:"text-center display-4 display-md-3 col-12",style:{fontFamily:"AudioWide"},children:"GAME LIBRARY"})}),Object(s.jsx)("p",{className:"text-center my-0",style:{fontSize:"1.2rem"},children:"Here is the list of game we have worked on. Scroll through the list below to explore our work:"}),Object(s.jsxs)("div",{className:"row flex-row flex-nowrap overflow-auto my-1 my-lg-5",children:[Object(s.jsx)(v,{name:"Bulls and Cows",link:"/bullsandcows",desc:"Bulls and Cows (also known as Cows and Bulls or Pigs and Bulls) is an old code-breaking mind or paper and pencil game for two or more players, predating the commercially marketed board game Mastermind.",image:"bullsandcows.jpg"}),Object(s.jsx)(v,{name:"Chopsticks",link:"/chopsticks",desc:"Chopsticks is a hand game for two or more players, in which players extend a number of fingers from each hand and transfer those scores by taking turns to tap one hand against another.",image:"chopsticks.png"}),Object(s.jsx)(v,{name:"Connect Four",link:"/connectfour",desc:"Connect Four is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. ",image:"connectfour.webp"}),Object(s.jsx)(v,{name:"Guess Who?",link:"/guesswho",desc:"Guess Who? is a two-player character guessing game, where each player secretly chooses one of 24 characters and the other player must use the process of elimination to identify the secret character.",image:"guesswho.jpg"}),Object(s.jsx)(v,{name:"Scotland Yard",link:"/scotlandyard",desc:"Scotland Yard is a board game in which a team of players controlling different detectives cooperate to track down a player controlling a criminal as they move around a board representing the streets of London.",image:"scotlandyard.jpg"})]})]})))},$=function(e){Object(m.a)(n,e);var t=Object(u.a)(n);function n(){return Object(h.a)(this,n),t.apply(this,arguments)}return Object(d.a)(n,[{key:"render",value:function(){return Object(s.jsx)(f.c,{children:Object(s.jsxs)(f.a,{children:[Object(s.jsx)(g,{}),Object(s.jsx)(y,{}),Object(s.jsx)(j,{}),Object(s.jsx)(x,{})]})})}}]),n}(i.a.Component),O=n(18),k=n(30),N=n(40),T=(n(86),function(){return Object(s.jsx)(b.a.nav,{className:"Sidebar",initial:{x:window.innerWidth>991?-100:0,y:window.innerWidth>991?0:100},animate:{x:0,y:0},transition:{duration:1},children:Object(s.jsxs)("ul",{className:"r-side-nav",children:[Object(s.jsx)("li",{className:"r-nav-logo",children:Object(s.jsxs)(l.c,{to:"/",className:"r-nav-link",children:[Object(s.jsx)(O.a,{className:"r-link-icon",icon:N.a}),Object(s.jsx)("span",{className:"r-link-text",id:"brand",children:"GAMELAB"})]})}),Object(s.jsx)("li",{className:"r-nav-item",children:Object(s.jsxs)(l.c,{to:"/bullsandcows",className:"r-nav-link",children:[Object(s.jsx)(O.a,{className:"r-link-icon",icon:k.c}),Object(s.jsx)("span",{className:"r-link-text",children:"Bulls and Cows"})]})}),Object(s.jsx)("li",{className:"r-nav-item",children:Object(s.jsxs)(l.c,{to:"/chopsticks",className:"r-nav-link",children:[Object(s.jsx)(O.a,{className:"r-link-icon",icon:k.b}),Object(s.jsx)("span",{className:"r-link-text",children:"Chopsticks"})]})}),Object(s.jsx)("li",{className:"r-nav-item",children:Object(s.jsxs)(l.c,{to:"/connectfour",className:"r-nav-link",children:[Object(s.jsx)(O.a,{className:"r-link-icon",icon:k.a}),Object(s.jsx)("span",{className:"r-link-text",children:"Connect Four"})]})}),Object(s.jsx)("li",{className:"r-nav-item",children:Object(s.jsxs)(l.c,{to:"/guesswho",className:"r-nav-link",children:[Object(s.jsx)(O.a,{className:"r-link-icon",icon:k.d}),Object(s.jsx)("span",{className:"r-link-text",children:"Guess Who?"})]})}),Object(s.jsx)("li",{className:"r-nav-item",children:Object(s.jsxs)(l.c,{to:"/scotlandyard",className:"r-nav-link",children:[Object(s.jsx)(O.a,{className:"r-link-icon",icon:k.e}),Object(s.jsx)("span",{className:"r-link-text",children:"Scotland Yard"})]})})]})})}),S=n(23),C=n.n(S),I=function(e){Object(m.a)(n,e);var t=Object(u.a)(n);function n(){var e;Object(h.a)(this,n);for(var s=arguments.length,a=new Array(s),i=0;i<s;i++)a[i]=arguments[i];return(e=t.call.apply(t,[this].concat(a))).state={bulls:"Bulls",cows:"Cows"},e.handleChange=function(t){e.setState(Object(p.a)({},t.target.id,t.target.value))},e.handleSubmit=function(t){t.preventDefault(),"Bulls"!==e.state.bulls&&"Cows"!==e.state.cows?Number(e.state.bulls)+Number(e.state.cows)>4?C()({title:"Invalid Input",text:"The sum of bulls and cows cannot exceed 4. Please check your input and try again",icon:"warning"}):"3"!==e.state.bulls||"1"!==e.state.cows?"4"!==e.state.bulls||"0"!==e.state.cows?(e.props.updateResponse(e.state),document.querySelector("#form").reset(),e.setState({bulls:"Bulls",cows:"Cows"})):C()({title:"Wooohoo!",text:"Looks like we guessed your number. But you need to click on the other button to end the game \ud83d\ude05"}):C()({title:"Invalid Input",text:"The given input is invalid. Please correct it and try again",icon:"warning"}):C()({title:"Invalid Input",text:"Please choose valid values for the number of Bulls and Cows",icon:"warning"})},e.handleSuccess=function(t){t.preventDefault(),C()({title:"The Secret Number was ".concat(e.props.guess),text:"We got it in ".concat(e.props.freq," guess").concat(1!==e.props.freq?"es":"","!"),icon:"success"}).then((function(){return e.handleNew(null)}))},e.handleNew=function(t){t&&t.preventDefault(),e.props.startNew(),e.setState({bulls:"Bulls",cows:"Cows"})},e.handleFailure=function(){C()({title:"Invalid Secret Number",text:"Looks like either the number you were thinking of was an invalid secret number (all four digits must be distinct) or you messed up in feeding the inputs. Maybe try again?",icon:"error",dangerMode:!0}).then((function(){e.handleNew(null)}))},e}return Object(d.a)(n,[{key:"render",value:function(){return"0000"===this.props.guess&&this.handleFailure(),Object(s.jsx)("div",{children:Object(s.jsxs)("div",{className:"text-center",children:[Object(s.jsxs)("h3",{className:"text-center mt-4",children:["Guess: ",this.props.guess]}),Object(s.jsxs)("form",{className:"form-group container",id:"form",onSubmit:this.handleSubmit,children:[Object(s.jsxs)("div",{className:"row justify-content-center mt-4",children:[Object(s.jsxs)("select",{className:"custom-select col-3 m-1",id:"bulls",onChange:this.handleChange,value:this.state.bulls,children:[Object(s.jsx)("option",{value:"Bulls",defaultValue:!0,disabled:"disabled",children:"Bulls"}),Object(s.jsx)("option",{value:"0",children:"0"}),Object(s.jsx)("option",{value:"1",children:"1"}),Object(s.jsx)("option",{value:"2",children:"2"}),Object(s.jsx)("option",{value:"3",children:"3"}),Object(s.jsx)("option",{value:"4",children:"4"})]}),Object(s.jsxs)("select",{className:"custom-select col-3 m-1",id:"cows",onChange:this.handleChange,value:this.state.cows,children:[Object(s.jsx)("option",{value:"Cows",defaultValue:!0,disabled:"disabled",children:"Cows"}),Object(s.jsx)("option",{value:"0",children:"0"}),Object(s.jsx)("option",{value:"1",children:"1"}),Object(s.jsx)("option",{value:"2",children:"2"}),Object(s.jsx)("option",{value:"3",children:"3"}),Object(s.jsx)("option",{value:"4",children:"4"})]})]}),Object(s.jsxs)("div",{className:"row justify-content-center mt-4",children:[Object(s.jsx)("button",{type:"submit",className:"btn btn-outline-primary mx-3",children:"Guess Again"}),Object(s.jsx)("button",{className:"btn btn-outline-success mx-3",onClick:this.handleSuccess,children:"Yup that's right!"})]})]})]})})}}]),n}(a.Component),_=function(e){Object(m.a)(n,e);var t=Object(u.a)(n);function n(){var e;Object(h.a)(this,n);for(var s=arguments.length,a=new Array(s),i=0;i<s;i++)a[i]=arguments[i];return(e=t.call.apply(t,[this].concat(a))).state={bulls:null,cows:null,left:[],all:[],guess:"0123",freq:1},e.choose_best=function(){var t,n=1e6;e.state.all.forEach((function(s){for(var a=[],i=0;i<10;i++)a.push(!1);for(var o=0;o<4;o++)a[s[o]-"0"]=!0;for(var r=[],l=0;l<5;l++)r.push([0,0,0,0,0]);e.state.left.forEach((function(e){for(var t=0,n=0,i=0;i<4;i++)a[e[i]-"0"]&&(n+=1),e[i]===s[i]&&(t+=1);n-=t,r[t][n]+=1}));for(var c=0,h=0;h<5;h++)for(var d=0;d<5;d++)c=Math.max(c,r[h][d]);c<n?(n=c,t=s):c===n&&e.state.left.includes(s)&&(t=s)})),e.setState({guess:t})},e.guess=function(){for(var t=e.state.bulls,n=e.state.cows,s=[],a=0;a<10;a++)s.push(!1);for(var i=0;i<4;i++)s[e.state.guess[i]-"0"]=!0;var o=[];e.state.left.forEach((function(a){for(var i=0,r=0,l=0;l<4;l++)s[a[l]-"0"]&&(r+=1),a[l]===e.state.guess[l]&&(i+=1);r-=i,i==t&&r==n&&o.push(a)})),e.setState({left:o},(function(){e.choose_best()}))},e.startNew=function(){for(var t,n=[],s=[],a="0";a<="9";a++)for(var i="0";i<="9";i++)for(var o="0";o<="9";o++)for(var r="0";r<="9";r++)t="",t+=a,t+=i,t+=o,t+=r,n.push(t),a!==i&&a!==o&&a!==r&&i!==o&&i!==r&&o!==r&&s.push(t);e.setState({bulls:null,cows:null,left:s,all:n,guess:"0123",freq:1})},e.updateResponse=function(t){e.setState({bulls:t.bulls,cows:t.cows},(function(){e.guess();var t=e.state.freq+1;e.setState({freq:t})}))},e}return Object(d.a)(n,[{key:"componentDidMount",value:function(){for(var e,t=[],n=[],s="0";s<="9";s++)for(var a="0";a<="9";a++)for(var i="0";i<="9";i++)for(var o="0";o<="9";o++)e="",e+=s,e+=a,e+=i,e+=o,t.push(e),s!==a&&s!==i&&s!==o&&a!==i&&a!==o&&i!==o&&n.push(e);this.setState({left:n,all:t})}},{key:"render",value:function(){return Object(s.jsxs)("div",{children:[Object(s.jsx)("h1",{className:"text-center",children:"Bulls and Cows Predictor"}),Object(s.jsx)(I,{updateResponse:this.updateResponse,guess:this.state.guess,freq:this.state.freq,startNew:this.startNew})]})}}]),n}(a.Component),P=n(3),W=n.n(P),M=n(8),A=n(4),B=n.n(A),F=(n(33),{introAndRules:"\nBulls and Cows is an old code-breaking game, where one person thinks of a secret \ncode and the other tries to guess it. **The code must consist of all distinct digits**.\nFor each guess, the player who is thinking of the secret code, gives the guesser a response\nin the form of [`x Bulls y Cows`]. The response is interpreted as:\n\n* [`x Bulls`] \u2192 `x` of the digits in the guess match the *digit* &nbsp;and *position* in the code.\n* [`y Cows`] \u2192 `y` of the digits in the guess match the *digit* &nbsp;**but not the** *position* in the code.   \n\nThis implies that *Bulls* &nbsp; and *Cows* are mutually exclusive in nature. Also, if the guesser makes the right guess, its response would be [`4 Bulls 0 Cows`].  \n#### **Example**:\nSay the secret number is `2673` and the guess is `1652`, then the response is [`1 Bull 1 Cow`]. Here, `6` is the **bull**\nsince it is in the 2nd position in both the codes and `2` is the **cow** since it is in the 1st position in the secret code\nand in the 4th position in the guess. The other two numbers are neither.\n\nThis game can be played with any number of digits (upto 10, since there are only 10 distinct digits), but the most common\npractice is to consider a 4 digit code. This is what we have explored too.         \n",implementation:"\nHere we have made a **Bulls and Cows Predictor** which can guess your code in at most 7 tries. Think of a secret code and\nand give it a go! *Try to make sure your input values for the number of **bulls** and **cows** is correct as wrong input would throw the predictor for a spin* \ud83e\udd16\ud83d\udd04\n    ",explanation:'\nBasically, the predictor tries to make the *best guess* each time, so that we can find the secret number in the fewest possible guesses.\nBut what does the term **best guess** actually mean?\n\nWe start with a list of all possible codes that the guess could be. This is the list of all 4 digit number with all 4 distinct digits.\nLet us call this list `S`. The idea is that, for each guess that we make, we have `14` possible responses.\nUsing the response, we eliminate all the codes from `S` that would not give the same response as the secret code when compared to our guess. \nEach response would eliminate a different number of items from `S`, and consequently, the resulting list would have\ndifferent sizes for every combination of guess and response. Now, for every possible guess, we need to identify the response that leaves\nthe largest number of items in the list. This is the worst case that could occur if we make this guess.\nWe essentially want to *optimise the worst case scenario* and then we choose the guess with the **best "worst case scenario"**. This guess is\nour **best guess**.\n\nSay we make a guess `abcd` and get a response [`x Bulls y Cows`]. We perform the elimination as mentioned above. Then for every possible guess that\nwe can make, we go through every possible response that we can get and we identify the response for which we have the fewest eliminations from `S`.\nWe assign the size of the filtered `S` as the `score` of that guess. Formally:\n\nThe **score of a guess** is the *largest number of items still in the list after elimination that that guess would lead to,\nout of all possible responses it can get*.\n\nAfter finding the *scores* for each guess that could be made, to find the most optimal guess for a particular round,\nwe then need to take the minimum of these scores that are available to us (since a lower score means that that guess has eliminated more of `S` in its worst case\nthat the others). You can see that **there is some mini-max (Minimum of the Maximum) stratergy involved here**:\n\n*We find the maximum possible size that could be left by each of the possible guesses and then pick the minimum of all those maximum sizes.*\n\nAt any point where we need to make a guess (after the first guess), say we choose one of `n` numbers as our guess, represented by:\n\n$$\nG_1, G_2\\dots G_n\n$$\n\nNow for each guess, we can get one of $m$ responses, represented by:\n\n$$\nr_1, r_2\\dots r_m\\ (m = 14 \\text{ in case of 4 digits})\n$$\n\nNow for each guess we want to see its worst case size left so we can define a $\\text{Score}$ for each guess $i$ and stores the worst case size of each reponse $r_j$\nas $s_{ij}$. Mathematically,\n\n$$\n\\text{Score}_i=max(S_{i\\ 1}, S_{i\\ 2}\\dots S_{i\\ m})\n$$\n\nAnd then to choose our best guess, we need to take the smallest of these scores:\n\n$$\n\\text{Best}=min(\\text{Score}_1, \\text{Score}_2\\dots \\text{Score}_n)\n$$\n\nThis results in the most optimal guess at each level. We are basically doing this till we find the secret code. Due to the optimal guessing stratergy, *we are\nable to find the secret code in atmost 7 guesses*. \n    ',process:"\nInitially we started out with just thinking about basic algorithms to obtain the code, nothing too efficient:\n\n### Our First Approach\n\nTo find the secret digits in the number, first we could *be sure of the digits that are actually in the secret code*\n\nWe can do that by checking the string of type $(i,\\ i\\ ,\\ i ,\\ i)$ where $i\\  \\epsilon \\ [0,\\ 9],\\ i\\ \\epsilon\\ Z$ and whenever the response is of the type,\n$1\\ \\text{Bulls}\\ 3\\ \\text{Cows}$ **we can be sure that that digit $\\ i$ exists in the secret code**. So to figure out all the digits *(for any length of secret code)* will take atmost 10 steps \nwhich is a constant amount of time.\n\nAfter figuring out the digits then we have $4!$ possibilities of what the the secret code can be. This felt like *a very brute force method* and as I expected was really not that efficient.\n\nSo Worst Case \u21d2 I could get my secret code in within $34$ steps, but that's not so good considering according to a research paper I read that any secret code based on the \nBulls and Cows game can be solved within **$7$ steps maximum.** \n\n---\n### Second Approach\nI actually just added this method as a baseline for any other algorithm that I created since it was a very basic procedure: **to just search the entire sample space**.\n\nSo we know that there are **4 distinct digits in the code**, that makes the total sample space's cardinality to be  $^{10}P_4$ ways which equals $5040$. \nNot too big a number for modern computers to brute force but still if you compare this to our *First approach*, its almost 150 times slower in worst case scenario, taking upto \n$5040$ steps in worst case.\n\n---\n### Lets talk about their scalability now\n\nAssume the length of the code to be some value $n$ where $n \\ \\leq\\ 10$  since its a requirement of Bulls and Cows that all the digits be *distinct.*\n\n- **First Algorithm**\n\nIts first part of obtaining the digits in the secret code will always take $10$  tries whatsoever in worst case and is fixed, since we are supposed to check \nfor all $i\\  \\epsilon \\ [0,\\ 9] \\ \\text{where}\\ i\\ \\epsilon\\ Z$.\n\nFor the second part we have the worst case scenario of $n!$ which can go upto $10! = 3628800$ (quite a big number). \n\nSo overall worst case complexity for first algorithm comes out to be $O(n!\\ + 10)\\ \\sim O(n!)$\n\n- **Second Algorithm**\n\nThis is a straight forward algorithm with its worst case scenario will be always going till the end of the sample space whose length will be  $^{10}P_n$, which \nequates to $^{10}C_n \\ *\\ n!$  where $n\\  \\epsilon \\ [1,\\ 10] \\ and\\ n\\ \\epsilon\\ Z$. Therefore the overall worst case complexity of the second algorithm is $O(n!\\ * ^{10}C_n)$ \n\nClearly since $^{10}C_n$ is a factor greater than $1$ here, the first algorithm fares out to be better in worst case complexity, even though its not the most ground breaking algorithm out there.\n\nWe first came accross the idea of **Response Classes**, which are essentially *the sections we can divide our response to any general guess that \nwe make regarding a code*. For example if for a particular guess, we get `[2 Bulls, 1 Cow]`, this would a response class.\n\n---\n### Proceeding towards hitting the \"Maximum 7 steps\" Mark\n\nFor Bulls and Cows where we guess a 4 digit code, we have 14 classes:\n\n- Case 1 -- `0 Bulls`\n    1. `0 Cows`\n    2. `1 Cow`\n    3. `2 Cows`\n    4. `3 Cows`\n    5. `4 Cows`\n- Case 2 -- `1 Bull`\n    1. `0 Cows`\n    2. `1 Cow`\n    3. `2 Cows`\n    4. `3 Cows`\n- Case 3 -- `2 Bulls`\n    1. `0 Cows`\n    2. `1 Cow`\n    3. `2 Cows`\n- Case 4 -- `3 Bulls`\n    1. `0 Cows`\n- Case 5 -- `4 Bulls`\n    1. `0 Cows`\n\nPlease note that from the general pattern of `5` choices in Case 1, `4` choices in Case 2, `3` choices in Case 3 and `1` choice in case 5, \nthere is an **anomaly in Case 4** since the case of `3 Bulls` and `1 Cow` can't exist as that is essentially `4 Bulls` and `0 Cows`.\n\nSo if we were to generalize the number of response classes for an $m$ digit number, we it is basically:\n$$\n\\sum_{i=1}^{m+1}i\n$$\n**But in this case, we are repeating a case of** &nbsp; `m - 1 Bulls` and `1 Cow`, so w can subtract $1$ from the summation to get the number of \nresponse classes for a general $m$ digit number:\n$$\n(\\sum_{i=1}^{m+1}i) - 1 = \\frac{(m + 1)(m + 2)}{2} - 1\n$$\nYou can also verify that for $m = 4$, total number of response classes comes out to be $14$. These response classes allow us to calculate how good a particular **guess** is\nin eliminating the maximum number of codes from sample space and therefore are on the key ideas of our algorithm. We maintain the response classes of a particular guess using\na $5$X$5$ matrix.\n\n---\n### Where Do we Make The Guesses From?\nWe now know how to find an **optimal guess** using response classes but, from where should we pick these guesses from?\n\nThe *intuitive response* would be from the list of remaining possible options, since the secret number must be one of those only.\n\nHowever, this is **putting a very large restriction on the sample space we can choose our next guess from**. It may so happen that no item in the remaining list \nhas the minimum score out of every possible guess that we can make (*For example, a number we might have eliminated before might be a better guess*). This means that \nrestricting ourselves to just this set of numbers may stop us from finding the optimal next guess.\n\nA *second response* would be the list of all possible 5040 distinct 4-digit numbers, since this would give us a larger sample space to choose from and could even yield a \nguess which has a much lower score than any of the other guesses that are in the remaining list, hence eliminating more items from the list than was previously possible.\n\nA *third*, more counter-intuitive, but the **most optimal approach** would be to pick the next guess from the set of all possible 4 digit numbers. This is quite \ncounter-intuitive since the we know that the secret number can only be a 4 digit number with distinct digits, and not just any 4 digit number. This approach would've been \nwrong if we were simply relying on luck and trying to guess the secret number, but *since we are using the process of elimination, we want to find the \nabsolute best guess that we can take, that would yield the minimum score* and we wo need even those numbers as guess that dont have all digits distinct.\n\nTake for example a guess 0123, and a response to it as `3 BULLS 0 COWS`. This means that one of the digits is wrong and the other 3 are correct. In a situation like \nthis, the guesses like 0000, 1111, 2222 and 3333, none of which is a valid secret number, could potentially give us an idea of which of the digits is wrong. Lets \nplay out the scenario:\n\nWe make the guess 0123 and get the response `3 BULLS 0 COWS`. This means that the secret number is in one of the following forms:\n\n- `x123`\n- `0x23`\n- `01x3`\n- `012x`\n\nWhere `x` is a digit from $0\\rightarrow9$, except for the digit that was there in the guess. Say our next guess is 0000 and we get `0 BULLS 0 COWS`. This means that there \nis no 0 in the secret number at all, and so the secret number must be of the form `x123`, which leaves only 9 possible outcomes. On the other hand, if we get \nthe response `1 BULL 0 COWS`, means that the secret number does have a 0 in its first digit's place and so its is of one of the other 3 forms.\n\nSo here taking numbers outside the standard space giave us an advantage and this shows why they can be handy in certain situations to minimize the steps required\nto guess the secret code. At the same time increasing the space from a maximum of $5040$ (4-digit numbers, distinct digits) to $1000$ (all 4-digit numbers) is *more \ncomputationally expensive*.\n    ",resource:"\n- Paper by Alexy Slovesnov\n- Paper by John Francis\n- Bulls and Cows Wikipedia page\n    "}),E=Object(c.f)((function(e){e.history;return window.scrollTo(0,0),null})),q={fontFamily:"AudioWide",fontSize:"2rem"},H={inlineMath:function(e){var t=e.value;return Object(s.jsx)(M.InlineMath,{math:t})},math:function(e){var t=e.value;return Object(s.jsx)(M.BlockMath,{math:t})}},z=Object(s.jsx)("div",{className:"my-4 py-2"}),Y=function(){return Object(s.jsxs)(s.Fragment,{children:[Object(s.jsx)(E,{}),Object(s.jsxs)("div",{className:"d-flex-column align-items-end mt-3 p-0",style:{fontFamily:"Oswald",marginLeft:window.innerWidth>991?"5rem":"0.5rem"},children:[Object(s.jsx)("h1",{className:"text-center",style:{fontSize:"3rem",fontFamily:"AudioWide"},children:"BULLS AND COWS"}),Object(s.jsx)("hr",{className:"mb-5"}),Object(s.jsxs)("div",{className:"container mb-5",style:{fontSize:"1.3rem"},children:[Object(s.jsx)("h2",{style:q,children:"\ud83d\udcdc INTRODUCTION AND RULES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:F.introAndRules}),z,Object(s.jsx)("h2",{style:q,children:"\ud83d\udc68\u200d\ud83d\udcbb IMPLEMENTATION"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:F.implementation}),Object(s.jsx)("div",{className:"row justify-content-center mt-4 mb-5",children:Object(s.jsx)("div",{className:"card py-5 col-12 col-md-8",children:Object(s.jsx)(_,{})})}),z,Object(s.jsx)("h2",{style:q,children:"\ud83d\udd75\ufe0f WOAH! HOW DOES IT WORK?"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:F.explanation,plugins:[B.a],renderers:H}),z,Object(s.jsx)("h2",{style:q,children:"\ud83c\udfc1 HOW DID WE GET HERE?"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:F.process,plugins:[B.a],renderers:H}),z,Object(s.jsx)("h2",{style:q,children:"\ud83d\udcdd REFERENCES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:F.resource}),z,Object(s.jsx)("hr",{className:"mb-1"}),Object(s.jsx)("h1",{className:"display-1 text-center",children:"\ud83d\udc02\ud83d\udc04"})]})]})]})},L={intro:"\nChopsticks is a game of strategy as well as basic math. It is also known as Finger Chess, Swords, Split, Magic Fingers, Chinese Fingers, \nCherries, Sticks, and Twiddly Dinks. There are many variations of rules though the overall theory and spirit of the game remain the same.\n    ",rule1:"\nBoth players start with both hands holding up one finger each.\n*The hands on the right side of the pictures below used for explaining the game belong to player 1 and the hands on the left belong to player 2.*\n    ",rule2:"\nOne player begins the game by tapping one of his fingers onto one of the other player's hands. \nLet's say `player 1` used his right hand to tap `player 2`'s right hand.\n    ",rule3:"\nThe second player now has to put up an additional one finger (**add the number of fingers the hand that had tapped with the pre-existing number \nof fingers**) on his right hand (the hand that was tapped), and *thus has two fingers up*.\n    ",rule4:"\nOnce a player has 5 fingers up, on one hand, the hand is dead and should be held as a fist behind the person's back. \n**A player cannot play with all five fingers up on one hand**.\n    ",rule5:"\n**A player loses when both his hands are dead (no fingers remaining up)**.\n\nLet's say `player 1` had three and two fingers up respectively on his right and left hands, and `player 2` had 0 and 2 fingers up respectively on \nhis left and right hands. By `player 1` tapping `player 2`'s right hand with their right hand,\n    ",rule6:"**Both the hands of &nbsp; `player 2` &nbsp;are dead, which means player 1 has won The game has ended.**",variant1:'\nThere are a few different rules one can adopt regarding when **one of the player\'s hand** is "dead" : \n    ',variant2:"\nLet's say it is player 2's turn, and they have 4 fingers up on their left hand and one finger on their right hand. Player 1 has three \nfingers up on their right and one on their left hand.\n\nThere are two variants of the game which will arise when player 2's left hand hits player 1's right hand,\n    ",variant3:"\nBringing a hand **back** from `dead` state:\n\n- An added move of being able to *redistribute the total numbers of fingers between the two hands*\n- Or an added move to be able to *stall by switiching fingers on either hand*\n    ",abst1:"\n### Using Arrays\nWe were using `2D-arrays` or vectors to *store the state of every turn*. The problem with this was that as the game progresses, the \n**number of states increase almost exponentially**. This means that our space complexity would tend to infinity.\n\n### Using Graphs\n\nWith the help of graphs, our space complexity would be a finite value. Each node would store the states of each player. We construct the node \nhaving $P_1$ in mind and hence the weights on the edges would be $\\infty$ when $P_1$'s state is $(0,0)$. The weight of all other nodes is $1$. \nLet $n$ be the number of fingers.\n\nThe number of nodes (N) is $N = \\frac{n^2(n+1)^2}{4}$\n\nThe maximum number of edges (E) is $E = \\frac{n^2(n+1)^2(n^2(n+1)^2-4)}{32}$\n\n### Time complexity\n\n$$\nO(n) = \\frac{n^2(n+1)^2}{4} [\\frac{1}{2}+\\frac{n^2(n+1)^2}{8}]\n$$\n\nTherefore it is $n^8$ complexity.\n\n### Visualizing the graphs\n\nThis is what a 3-turn demonstration looks like, where $P_1$ is player one and $P_2$ is player two.\n    ",abst2:"\nWhere each node in the actual graph is going to have the states of both players $(P_1, P_2)$. **The green and purple colored paths are the possible paths for the player to \nwin the game** &nbsp; (1 and 2 just represent the path number). Here the $\\text{root node is}\\ ((1,1),(1,1)),  P_1\\ wins\\ is\\ ((x,y),(0,0))$ and every \nother node is $((x_1,y_1),(x_2,y_2))$.\n    ",algo1:"\n### DFS or BFS\n\nThe idea is to DFS or BFS through the graph *starting at the root node* till we find the node which has a $(0,0)$ state for the opponent \nand **avoiding the path if we come across our own $(0,0)$ state**.\n\n#### Time complexity\n\nThe time complexity of performing DFS or BFS once is $O(n^8)$. We would *have to perform this at every turn and since we cannot determine the \nnumber of turns the game will run for*, this might not be the best solution if we have to repeat it several times.\n\n---\n\n### Floyd Warshall\n\nRunning Floyd Warshall on the graph would give us **a distance matrix which contains the distance between any two given states**. During run time we \nonly need to lookup this matrix and find the distance. \n\n#### Advantages\n\n1. We get the information on how many moves it would take for us to win from the given state and if it is not possible to win at all.\n2. An additional dfs will also give us the path or moves to make in order to win.\n\n#### Time complexity\n\nThe time complexity to run Floyd Warshall is $O(n^{12})$. However, **we will have to run this only once and lookup from this matrix**. Also, the \ndfs can be modified for finding the path as we know the number of moves. This *dfs will be programmed to stop after* $k$ *number of moves \nto increase efficiency*.\n\n---\n\n### Final Solution\n\nWe construct the graph by simulating the game for an arbitrary $r$ rounds (*basically takes every state it comes across and links it to \nthe previous state it has come from*) which is complexity of $O(n^8)$. Then *we run Floyd Warshall to obtain the distance matrix which is of \ncomplexity* $O(n^{12})$. \n\nFurther, a **hint button** that tells the player what the next move should be is done by running a DFS with the *number \nof moves as the constraint whose complexity is* $m$ moves. The pseudocode is:\n```\nConstruct the weighted graph \nFloyd Warshall with n nodes\nif hint then DFS with m moves\n```\n\n---\n### Scalability of The Algorithm\nIn case a different specie with say F fingers and H hands want to play a N player game, \n\nThe complexity = $F^3(N+H)$\n\nWe can model a more general model if required, but with respect to the game-chopsticks we assume that only $5$ fingers will be present on \nevery hand and that is constant. To give a reference of the scale here is a table:\n    "},D={fontFamily:"AudioWide",fontSize:"2rem"},G={inlineMath:function(e){var t=e.value;return Object(s.jsx)(M.InlineMath,{math:t})},math:function(e){var t=e.value;return Object(s.jsx)(M.BlockMath,{math:t})}},X=Object(s.jsx)("div",{className:"my-4 py-2"}),R=function(){return Object(s.jsxs)(s.Fragment,{children:[Object(s.jsx)(E,{}),Object(s.jsxs)("div",{className:"d-flex-column align-items-end mt-3 p-0",style:{fontFamily:"Oswald",marginLeft:window.innerWidth>991?"5rem":"0.5rem"},children:[Object(s.jsx)("h1",{className:"text-center",style:{fontSize:"3rem",fontFamily:"AudioWide"},children:"CHOPSTICKS"}),Object(s.jsx)("hr",{className:"mb-5"}),Object(s.jsxs)("div",{className:"container mb-5",style:{fontSize:"1.3rem"},children:[Object(s.jsx)("h2",{style:D,children:"\ud83d\udcdc INTRODUCTION"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:L.intro}),Object(s.jsxs)("div",{className:"row align-items-center",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.rule1})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/0.jpeg",alt:""})})]}),Object(s.jsxs)("div",{className:"row align-items-center",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/1.jpeg",alt:""})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.rule2})})]}),Object(s.jsxs)("div",{className:"row align-items-center",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.rule3})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/2.jpeg",alt:""})})]}),Object(s.jsx)("div",{className:"row justify-content-center",children:Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.rule4})})}),Object(s.jsxs)("div",{className:"row align-items-start",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/4.jpeg",alt:""})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/3.jpeg",alt:""})})]}),Object(s.jsxs)("div",{className:"row align-items-center",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/5.jpeg",alt:""})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.rule5})})]}),Object(s.jsxs)("div",{className:"row align-items-center",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.rule6})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/6.jpeg",alt:""})})]}),X,Object(s.jsx)("h2",{style:D,children:"\ud83c\udccf VARIANTS"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:L.variant1}),Object(s.jsxs)("div",{className:"row align-items-center",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.variant2})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/7.jpeg",alt:""})})]}),Object(s.jsxs)("div",{className:"row align-items-start",children:[Object(s.jsxs)("div",{className:"col",children:[Object(s.jsx)("img",{className:"img-fluid figure-img mx-auto d-block",src:"/assets/ContentImages/Chopsticks/8.jpeg",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"Either player 1's right hand is dead, as it exceeded the total of 5 fingers"})]}),Object(s.jsxs)("div",{className:"col",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/Chopsticks/9.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:" Player 1 right hand is left with two fingers as leftovers (mod 5). The five that count as dead are subtracted leaving player 1's right hand with two fingers up."})]})]}),Object(s.jsxs)("div",{className:"row align-items-center",children:[Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Chopsticks/10.jpeg",alt:""})}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)(W.a,{source:L.variant3})})]}),X,Object(s.jsx)("h2",{style:D,children:"\ud83d\udd8b\ufe0f ABSTRACTION"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:L.abst1,plugins:[B.a],renderers:G}),Object(s.jsx)("div",{className:"text-center mb-4",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",style:{height:"40rem",width:"auto"},src:"/assets/ContentImages/Chopsticks/11.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"This is only the intuition for the game flow and not how the actual graph looks."})]})}),Object(s.jsx)("div",{className:"text-center",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",style:{height:"40rem",width:"auto"},src:"/assets/ContentImages/Chopsticks/12.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"This is what actual graph looks like"})]})}),Object(s.jsx)(W.a,{source:L.abst2,plugins:[B.a],renderers:G}),X,Object(s.jsx)("h2",{style:D,children:"\ud83e\uddee ALGORITHM"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:L.algo1,plugins:[B.a],renderers:G}),Object(s.jsxs)("table",{class:"table table-sm table-bordered",style:{"text-align":"center"},children:[Object(s.jsx)("thead",{children:Object(s.jsxs)("tr",{children:[Object(s.jsx)("th",{scope:"col",children:"No. of Players(K)"}),Object(s.jsx)("th",{scope:"col",children:"Complexity(Cm)"}),Object(s.jsx)("th",{scope:"col",children:"Time(T)"})]})}),Object(s.jsxs)("tbody",{children:[Object(s.jsxs)("tr",{children:[Object(s.jsx)("th",{scope:"row",children:"2"}),Object(s.jsx)("td",{children:Object(s.jsx)(M.InlineMath,{math:"5^{12}"})}),Object(s.jsx)("td",{children:Object(s.jsx)(M.InlineMath,{math:"<\\ 10 \\text{ seconds}"})})]}),Object(s.jsxs)("tr",{children:[Object(s.jsx)("th",{scope:"row",children:"3"}),Object(s.jsx)("td",{children:Object(s.jsx)(M.InlineMath,{math:"5^{18}"})}),Object(s.jsx)("td",{children:Object(s.jsx)(M.InlineMath,{math:"<\\ 20 \\text{ minutes}"})})]}),Object(s.jsxs)("tr",{children:[Object(s.jsx)("th",{scope:"row",children:"4"}),Object(s.jsx)("td",{children:Object(s.jsx)(M.InlineMath,{math:"5^{24}"})}),Object(s.jsx)("td",{children:Object(s.jsx)(M.InlineMath,{math:"<\\ 3 \\text{ months}"})})]})]})]}),Object(s.jsx)("hr",{className:"mb-1"}),Object(s.jsx)("h1",{className:"display-1 text-center",children:"\ud83e\udd62"})]})]})]})},U={intro:"\nConnect-Four is a *game for two players*. Both have **`21 identical coins`**. In the standard form of the game, one set of coins is yellow, \nand the other is red. *You play the game on a vertical, rectangular board consisting of `7` vertical columns of `6` rows each*. Each time \na player puts a coin down, it falls to the lowest unoccupied block in that column. Players make a move in turns.\n\nIf a player connects four coins either horizontally, vertically or diagonally, they win. Occupying each of the 7x6 blocks such that \nno other move is possible, and ensuring that there is no winning player, entails the draw condition.\n\nNow, some definitions to make referencing the board easier. *The 7 columns are labelled 'a' through 'g', while the rows are \nnumbered 1 through 6*. In this way, the *lowest square in the middle column is called* `d1`. For convenience's sake, we are taking \nthe **first player as White (W) and second as Black (B) (similarities to Chess)**.\n    ",approach:"\nBefore you show off your excellent techniques, we need to first prove that the dumb approach does not work. It is easy to \nsee that the number of possible positions is at most $3^{42} (\\geq 10^{20})$. This upper bound is a very crude one and can be brought into \nbetter proportions. For this purpose, a program was written in the C programming language, which is mentioned later. \nFor the standard, `7 x 6` board, the program saw an upper bound of $7.1* 10^{13}$.\n\nSo, **too many possibilities, significantly less accuracy, brute force is not an efficient approach**. A player cannot win just by instantiating \neach possible board and trying to follow it. You are a human after all, not a computer \ud83d\ude1b\n    ",boards:"\nLet's start small. Consider a board of `n columns`, but only `2 rows`. My **claim is that Black will never lose a game on this board**. \nEven if n were to be practical infinity.\n\nThis is how B should play.\n\n1. Pair up all the n rows in groups of 2. If n is odd let the nth row be alone.\n2. If W plays in row 1, play in row 2 (pair). If W plays in row 2, play in row 1.\n3. If W plays in row N, play in row N.\n\nThis will always result in a draw, since only way W could win is if it were to get its coin in 4 consecutive rows side by side. \nThis is prevented by B.\n\nAnother solved board is with `2n rows` (even) and `columns \u2264 6`. This strategy could also be used for ensuring B always draws.\n\n1. If W plays in columns 1, 2, 5 or 6, B plays in the same column.\n2. If W plays for the first time in column 3 or 4, B plays in the other column.\n3. Otherwise, if W plays in column 3 or 4, and B can still play in it, B plays in the same column\n4. If W plays in column 3 or 4, and B can not play in it, B plays in the other column.\n\nSince B never allows a vertical 4 for W, that is out of the question. For horizontal 4 at row 1, B ends up occupying at least 1 of \nthe two bottom columns, hence denying that for W as well.  For any other horizontal 4, it is only possible in odd rows for W. But \nin column 3 and 4, B ends up having at least 1 in either of the two in all odd rows. Diagonal is not possible at all since W will \nhave all coins at odd rows in column 1, 2, 5 and 6.\n    ",threat1:"\n#### **Useless Threat**\n    ",threat2:"\nThe threats by **W** in `row 3,4,5` are considered to be useless, due to the threat by **B** in row 2. Since *W cannot move in `column 2` and `6`, \nit has to fill `column 7`*.  Even number of rows mean that W will still have the turn when column 7 is filled, meaning B will end up winning.\n\nWhether a threat is useless or useful is dependant on control of Zugzwang (explained later). \n\n#### **Odd Even Threat**\n\nA threat is only useful if a player is forced to play in a row just below that of the threat. Usually that happens when other columns are filled. \nIn such cases, **generally**, *W has only odd rows, and B has even rows*. \n\n*Black has odd threats, and White has even*. If they are in the same column, the lower threat will win (as seen above)\n\nGenerally speaking, W threat is stronger than that of B. Here is how everything rolls out:\n\n- W has odd, B has even threat: W will win.\n- W has even, B has even threat: B will win.\n- W has even, B has odd threat: Draw.\n- W has odd, B has odd threat: Draw.\n\nA simple example consisting of multiple threats is:\n    ",threat3:"\nHere, **B has odd threat** at `c3` and **W has odd threat** at `f3`. Going by the table, it should be a draw. Lets play it out. **W** has to give up its own threat \nto play the game, which would ideally result in a draw, since **B** will have to give up its threat in `c`. But what happens is that **B** \ngets to create a new threat at `c2` due to coin at `f5`. This gives B consecutive threats, and thus it wins. \n\nThis tells us that **though parity of threats tells us a good amount about the winner, we need to be careful about new threats**.\n    ",zug1:"\nThis is a very basic but powerful concept in Connect 4. **Zugzwang** basically means to force a player to make a move they would rather not make. \nThis is due to the *simple rule that they have to make a move, and the constraints of the board*. \n\n#### **Initial Position**\n\n**W always moves first**. Therefore B always is in a position to play follow up, hence to control the Zugzwang. Suppose B plays follow up from the beginning, \nyou would end up with a board like this:\n    ",zug2:"\nThough this is an illegal position, *it is interesting to note who won first*. Since **W** controls whole first row, naturally **W** won the game first. \nThis shows that follow up *is not a good strategy at the start of the game* for **B**. \n\n#### **Other positions**\n\nThe following board represents a position where **W** is in control of the Zugzwang:\n    ",zug3:"\nHere, **W** has an odd threat in `column a`. Knowing this, **B** won't play there. Since on the rest of the board, odd number of squares are remaining, \nwhoever plays first here, the opposite will have to play in `column a`. Since **W** is playing the first, it can control the zugzwang to force **B** to play \nat `a2`. The only option **B** has to go against the zugzwang and connect its 4 men, but still, it is **W's game to lose**. \n\n**In this case, B has control of Zugzwang due to even threats**\n    ",zug4:"\n**B** and **W** *ideally do not want to be the first to play in* `b` or `f`. Other than these 2, *the total number of boxes remaining is even*. This means whoever plays \nfirst here, will be the player **forced to play first in either column* `b` or `f`. That means at the end, **W** will have to play in `b1` or `f1`, thus losing. \n**B** is in complete control of Zugzwang here and can play follow up.\n    ",strat1:"\nA formal definition is given of the nine rules which are used to refute potential threats of the opponent. These can be only applied by the player in control of the \nZugzwang. These are always applied in the places opponent has to move. \n\n#### **Claimeven**\n\nThis makes direct use of the fact that player in control of Zugzwang can get all even unclaimed positions, giving odd positions to the other.\n    ",strat2:"\n**B** is in control of Zugzwang here since **W doesn't have any threat**. Here, if B were to use claimeven, he could end up getting a draw, since any threat of W will \nneed to have a coin in even row, which will not be possible. \n\n#### **Baseinverse**\n\nThis is based on the logic that a player cannot play two directly playable moves in one turn. Therefore once the opponent has made the move, controller of \nZugzwang can still cover the other position.\n    ",strat3:"\nHere, if W cannot play in a1 and b1 at the same time. That means if W plays in a1, B plays in b1, and vice versa. Thus the threat is nullified.\n\n#### **Verticle**\n\nSimilar to Baseinverse, this is based on the fact that a player cannot play two directly playable moves in a single column in one turn. Depending on the \nopponent, the player controlling the Zugzwang can either play second or first in the column to prevent a verticle 4. \n\n#### **Aftereven**\n\nAftereven uses a special side-effect of the usage of one or more Claimevens. If a group can be completed by the controller of zugzwang, \nthen they can complete the whole board using claim even, and then complete that group:\n    ",strat4:"\nHere, **B** can use aftereven to complete the group at either `b2` or `f2`. Here, then **B** can use claimeven to finally force **W** to play in either `b1` or `f1`. \nThis is called as aftereven, where you can form a group and win by using claimevens.\n\n#### **Lowinverse**\n\nLowinverse is based on the fact that two odd numbers when summed give an even number. Normally, controller of Zugzwang will play lowest even square of the column \ncontaining odd number of empty squares. But when we have two columns (doesn't have to be consecutive) having odd number of empty squares, this \nwill force the opponent to play first. In such a way controller of zugzwang gets to take the odd square above the opponent. \n\n#### **Highinverse**\n\nThis is based on the same principle  as that of lowinverse:\n    ",strat5:"\nIn lowinverse, we would consider `c2, c3, d2, d3` as important. Here we consider `c4` and `d4` as important too. Highinverse is nothing but a \ncombination of lowinverse and claimeven. What this does is say **W** plays in `c2`, then using lowinverse **B** can get `c3`. Then **B** (controller of Zugzwang) \nconvert `d3 and d4` into a claimeven, to get `d4`. In such a way **B** ends up getting `c3` and `d4`. \n\n#### **Baseclaim**\n\nThis is a combination of Baseinverse and Claimeven:\n    ",strat6:"\nHere, W can possibly have 3 threats formed: `b1-e1, c1-f1, b1-e4`(diagonal). **B** needs to play in a way to counter this. \n\n- **W** plays in `b1`, **B** plays in `e1` and then uses Claimeven at `c1-c2` to prevent `b1-e4`.\n- **W** plays at `c1`, **B** plays in `e1` and then uses Baseinverse at `b1-c2` to prevent `b1-e4`.\n- **W** plays at `e1`, **B** plays in `c1` and then uses Baseinverse at `b1-c2` to prevent `b1-e4`.\n\nIn such ways **B** can nullify all of **W**'s threats.\n\n#### **Before**\n\nThis is a combination of Claimeven and Vertical:\n    ",strat7:"\nHere `b4-e1` is the Before group. Since `b4` and `e1` are still empty, this means it works for all  groups needing both `b5 and e2 (b5-e2)`. \nHere, before uses the squares `b4-b5` and `e1-e2`. As soon as `b4` is played, `b5` is played, and same with `e1-e2`. This will ensure **B** \ncompleting `b4-e1` or preventing **W**'s `b5-e2`. In both cases `b5-e2` is a useless threat. \n\nIt basically means that if there is a before group, the opponent cannot claim all the unclaimed squares in the threat column.\n\n#### **Special Before**\n    ",strat8:"\nWe use `d2-g2` as the before group. This can contain claim evens at `f1-f2` and `g1-g2` and vertical at `e2-e3`. We need to use baseinverse to solve `a1-d1`, \nwhich would give **W** a possibility of `b1-e4`. To combat this, we can use claimeven to get `e4`. This claimeven, however, is conflicting with vertical at `e2-e3`. \n\nThe only reason **B** needs to play `e3` is to prevent `d3-g3`. So **B** can play `d3` as well. If **W** were to play at `d3` before, then **B** \nshould immediately get `e2` to continue with the Before play. Therefore to play a Special Before, we need a before group `(d2-g2)` with one of the \nempty squares as directly playable (`e2`). Furthermore, we need another playable square (`d3`).\n\n#### **Combination**\n    ",bw:"\n#### **Black**\n\nWe have developed a set of rules which can be used to show that certain potential threats can be refuted. Since some of the rules depend on Zugzwang, it is important \nthat the person who applies them is in control of the Zugzwang.\n\n**B** is in control of Zugzwang until **W** creates an odd threat. Till then if **B** just plays using the strategy. If **W** were to create a good threat (odd threat), \n**B** is no more in control of Zugzwang. Here we observe that no matter what B does from here on out, there generally will not be any set of rules which can refute that threat.\n\nFrom this we can conclude that we do not need to check who controls the Zugzwang for **B** before applying the rules. For if *B is in control, we can apply the rules, \nif not, it doesn't matter what B does*.\n\n#### **White**\n\n**W** needs an odd threat to gain control of Zugzwang. Once it has that, he just needs to follow the strategic rules to fill up the rest of the board. *If W has \nmore than one odd threat, it can choose from which poison to kill B from*.\n\n## Victor\n\nA position in which **W** has to move, can be evaluated as *B as controller of Zugzwang, and vice versa*.  For **W** as a controller of Zugzwang, evaluation must be done \nremoving the odd column out of viable options. *The evaluation begins with finding all possible instances of the $9$ strategic rules*.\n\nFor each position where any rule is applied, it is seen whether it can solve a problem or not. Each application of one of the rules which solve one or more \nproblems is stored. These are called Solutions. This results in a list of solutions, where each solution is stored as a Struct. Struct consists of fields describing the \nrule, and the positions involved. Furthermore for each solution we have a list of groups solved by that solution.\n\nWe also **create a map with problem as the key and list of pointer(s) to the solution as the values**. After all this, we need to see which solutions \ncan work together and which cannot. To work this out, solutions are seen as nodes of an undirected graph. If two solutions can't be used simultaneously, \nthey are connected. These connections are stored in an adjacency matrix. *To fill it, it is important to know type of solutions and squares involved. Once \nit is filled, it is a normal square array*.\n\nIf we see the problems as nodes, too, and we connect a solution and a problem if the solution solves the problem, and no problems are connected, we can solve it \nas a pure graph problem.\n\nGiven are two sets of nodes, S(olutions) and P(roblems). We try to find an allowable (in graph\ntheory: independent) subset C(hosen) of S, with the property that P is contained in B(C) (*the set of all neighbours of nodes in C*)\n\n*It can be solved using a simple backtracking algorithm*.\n\n```cpp\nvoid FindChosenSet(P, S)\n{\n    if (P == EmptySet) {\n        Eureka(); // We have found a subset C \n    }\n    else {\n        MostDifficultNode = NodeWithLeastNumberOfNeighbours(P);\n        for (auto neighbours: MostDifficultNode ) {\n            FindChosenSet(P - { MostDifficultNode },\n                S - AllNeighbousrsOf(ChosenNeighbour));\n        }\n    }\n}\n```\n\nIf a set of solutions is found for a given position, these **solutions show the plan which has to be\nfollowed to play the game** until the desired result (win for White, or at least a draw for Black) is\nreached.\n    ",fft:"\nLets assume we have an oracle. This oracle cannot predict who will win, but for any given state of board, give the best possible outcome. Let us assume \nthat we play such that for each state of board, we ask for help from the oracle. **Therefore it is a 'perfect' game. In such case, if W wins, does that mean \nW will always win if it were a perfect game?** \n\nThe thing is, if *for B we were to choose that draw is fine, it will not change any result*. Since oracle predicts the best move, if the second scenario gives \ndifferent result, that would mean Oracle could have chosen the best move, but did not. That is contradictory. That means that whoever will win with the help of \nthe Oracle, is always at an advantage.\n\nAnother thought to explore is *number of legal ways to arrange* $N$ coins in board. For now, we take the board to be the standard $7 \\times 6$ board.\n    ",resource:"\n- Resources by Victor Allis\n- Alpha Beta Pruning based heuristics\n- Principles and Tehniques BY Stanford\n- C4 Numbers by oeis org\n- Math oriented resources behind Connect-4\n    "},Z={fontFamily:"AudioWide",fontSize:"2rem"},V={inlineMath:function(e){var t=e.value;return Object(s.jsx)(M.InlineMath,{math:t})},math:function(e){var t=e.value;return Object(s.jsx)(M.BlockMath,{math:t})}},K=Object(s.jsx)("div",{className:"my-4 py-2"}),J=function(){return Object(s.jsxs)(s.Fragment,{children:[Object(s.jsx)(E,{}),Object(s.jsxs)("div",{className:"d-flex-column align-items-end mt-3 p-0",style:{fontFamily:"Oswald",marginLeft:window.innerWidth>991?"5rem":"0.5rem"},children:[Object(s.jsx)("h1",{className:"text-center",style:{fontSize:"3rem",fontFamily:"AudioWide"},children:"CONNECT FOUR"}),Object(s.jsx)("hr",{className:"mb-5"}),Object(s.jsxs)("div",{className:"container mb-5",style:{fontSize:"1.3rem"},children:[Object(s.jsx)("h2",{style:Z,children:"\ud83d\udcdc INTRODUCTION AND RULES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.intro,plugins:[B.a],renderers:V}),K,Object(s.jsx)("h2",{style:Z,children:"\ud83d\udee3\ufe0f APPROACHING THE GAME"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.approach,plugins:[B.a],renderers:V}),K,Object(s.jsx)("h2",{style:Z,children:"\u2684 SOME POSSIBLE BOARDS"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.boards,plugins:[B.a],renderers:V}),K,Object(s.jsx)("h2",{style:Z,children:"\u2620\ufe0f THREATS"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.threat1,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/1.png",alt:""})}),Object(s.jsx)(W.a,{source:U.threat2,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/2.png",alt:""})}),Object(s.jsx)(W.a,{source:U.threat3,plugins:[B.a],renderers:V}),K,Object(s.jsx)("h2",{style:Z,children:"\u2742 ZUGZWANG"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.zug1,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/3.png",alt:""})}),Object(s.jsx)(W.a,{source:U.zug2,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/4.png",alt:""})}),Object(s.jsx)(W.a,{source:U.zug3,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/5.png",alt:""})}),Object(s.jsx)(W.a,{source:U.zug4,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/6.png",alt:""})}),K,Object(s.jsx)("h2",{style:Z,children:"\ud83d\udd75\ufe0f\u200d\u2642\ufe0f STRATERGIES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.strat1,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/7.png",alt:""})}),Object(s.jsx)(W.a,{source:U.strat2,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/8.png",alt:""})}),Object(s.jsx)(W.a,{source:U.strat3,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/9.png",alt:""})}),Object(s.jsx)(W.a,{source:U.strat4,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/10.png",alt:""})}),Object(s.jsx)(W.a,{source:U.strat5,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/11.png",alt:""})}),Object(s.jsx)(W.a,{source:U.strat6,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/12.png",alt:""})}),Object(s.jsx)(W.a,{source:U.strat7,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/13.png",alt:""})}),Object(s.jsx)(W.a,{source:U.strat8,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/14.png",alt:""})}),K,Object(s.jsx)("h2",{style:Z,children:"\u26ab\u26aa BLACK AND WHITE"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.bw,plugins:[B.a],renderers:V}),K,Object(s.jsx)("h2",{style:Z,children:"\ud83e\udde0 FOOD FOR THOUGHT"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.fft,plugins:[B.a],renderers:V}),Object(s.jsx)("div",{className:"col",children:Object(s.jsx)("img",{className:"img-fluid mx-auto d-block",src:"/assets/ContentImages/Connect4/15.png",alt:""})}),K,Object(s.jsx)("h2",{style:Z,children:"\ud83d\udcdd REFERENCES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:U.resource}),Object(s.jsx)("hr",{className:"mb-1"}),Object(s.jsx)("p",{className:"text-center",style:{fontSize:"0.8rem"},children:"\u2063\u26aa\u26aa\u26aa\u26aa\u26aa\u26aa\u26aa"}),Object(s.jsx)("p",{className:"text-center",style:{fontSize:"0.8rem"},children:"\u26aa\u26aa\u26aa\u26aa\u26aa\u26aa\u26aa"}),Object(s.jsx)("p",{className:"text-center",style:{fontSize:"0.8rem"},children:"\u26aa\u26aa\u26aa\u26aa\u26aa\u26aa\u26aa"}),Object(s.jsx)("p",{className:"text-center",style:{fontSize:"0.8rem"},children:"\u26aa\u26aa\ud83d\udd35\ud83d\udd34\u26aa\u26aa\u26aa"})]})]})]})},Q={introAndRules1:"\n**Guess Who?** is a two-player character guessing game. Each player starts the game with a board that includes cartoon\nimages of 24 people and their first name with all the images standing up. Each player selects a card of their choice\nfrom a separate pile of cards containing the same 24 images. The object of the game is to be the first to determine\nwhich card one's opponent has selected. Players alternate asking various yes or no questions to eliminate candidates\nsuch as *\"Does your person wear glasses?\"* The player will then eliminate candidates based on the opponents response\nby flipping those images down until only one is left. The player who is able to guess the opponent's character in the\nfewest moves is the winner. \n    ",quickAnalysis1:"\nTo get started with the formulation of a simple formula of the game of Guess Who?, we should first analyze the chance or\nprobability involved in the gameplay.\n\nWe will try to explain the ideas to the best of our abilities, as we have understood from this video:\n    ",quickAnalysis2:"\nMy initial thoughts on Guess Who:\n\n* There can be two ways you can go about asking questions:\n    1. Ask a specific question \u2192 If the answer is **NO** then it would result in very few cards being flipped down.\n    On the other hand if the response is **YES** then a lot of cards can be eliminated in a single go.\n    \n    2. Ask a broad question \u2192 Both **YES** and **NO** responses would result in a moderate number of cards being flipped down.\n* Here we will exploit the broad questioning strategy as the specific question strategy relies very heavily on luck, which is inherently\ndifficult to quantify.\n* On an average (looking at any of the characters present in the game of Guess Who?), every feature (such as red hair, bald, glasses,etc)\nis shared by around 5 people.\n* A very well framed broad question can ideally result in hald the characters being flipped down every time. So given 24 characters, it\nshould take about 5 moves to narrow down the search space to a single character. Lets us analyze this!\n    ",deeperDive1:"\nThe overall problem here becomes that of eliminating maximum possible characters with a single question each time.\n\nNow since there are 24 characters, you need around $\\log_2 24$ moves, which rounds up to 5 moves on average. Let us simulate this in a fair sample space\nwhere now there is an opponent (finally!). We can model how the opponent plays by collecting sample moves from a lot of games played with a lot\nof people. This results in the following bell curve:\n    ",deeperDive2:"\nHere the horizontal axis of the curve represents the number of moves that you played to get all characters eliminated. The vertical axis is the probability\nin percentage of thta happening. The bell curves here have standard results of how each bell curve with an average at the median would look like. Here,\nthe average is 5 with the highest probability ($38\\%$). Since these values were calculated independently, by multiplication law, the values in the grid are the\npercentages on the left multiplied by the percentages above. For example $24\\% \\times 38\\% = 9\\%$.\n\nWhat the colors represent:\n\n* \ud83d\udd35 \u2192 We **LOSE** as the number of moves used by us is more than that used by the opponent\n* \ud83d\udd34 \u2192 We **WIN** as the number of moves used by us is fewer than that used by the opponent\n* \ud83d\udfe1 \u2192 It is a **TIE** as the number of moves used by us is equal to that used by the opponent\n\nSo if you add up all the red squares, we get $63\\%$ chance of winning with this broad questioning strategy.\n\nThe data being used here is for an opponent that is quite clever, i.e. they are also playing close to optimal. For an average opponent the win rate is\nexpected to increase to about $80\\%$. We can further push it to $96\\%$ if we challenge the opponent to a *Best of Five Games*, but that is irrelavent here.\n\nNow let us connect this to the world of algorithms...\n    ",maximumCoverageProblem:"\nThe **Maximum Coverage Problem** is a famous problem in the field of algorithms. Formally:\n\n*As input you are given several sets and a number $k$. These sets may have some elements in common. You must select at most $k$ of these\nsets such that the maximum number of elements are covered, i.e. the union of the selected sets has maximal size.*\n\nInstance: A number $k$ and a collection of sets $S = {S_1, S_2, \\dots, S_m}$.\n\nObjective: Find a subset $S' \\subseteq S$ of sets such that $\\vert S'\\vert \\leq k$ and the number of covered elements \n$\\left\\vert \\bigcup\\limits_{S_i\\in S'} S_i \\right \\vert$ is maximized.\n\nThe above mentioned problem is however, NP-Hard \ud83d\ude22. Fortunately for us, there is a greedy approximation which has an approximation factor of\n$1-\\frac{1}{e}$ which comes out to be about $0.63$. Here approximation factor means the ratio of the answer obtained by the greedy solution\nto the actual optimal solution.\n\nHere is the greedy pseudocode for Maximum Coverage:\n\n```\nInput: Universal Set U and the number k and the subsets\n\nfor i in 1 to k:\n    do:\n        pick the set with maximum elements\n    done\n```\n\nNow, we prove that the approximation factor comes to be $1-\\frac{1}{e}$.\n\nLet:\n\n* $a_i$ \u2192 Newly covered elements at the $i^{th}$ iteration\n* $b_i$ \u2192 Total elements covered till the $i^{th}$ iteration\n* $c_i$ \u2192 Elements left uncovered at the $i^{th}$ iteration\n* $OPT$ \u2192 Optimal Answer\n* $c_i = OPT - b_i$\n\n**Lemma 1.** *Number of newly covered elements at the $(i+1)^{th}$ iteration is always greater than or equal to $\\frac{1}{k}$ of the number\nof uncovered elements after the $i^{th}$ iteration, i.e. $a_{i+1} \\geq \\frac{c_i}{k}$.*\n\n**Proof**. Optimal solution covers $OPT$ elements at $k$ iterations. That means, at each iteration there should be some set in $U$ whose size\nis greater than or equal to the $\\frac{1}{k}$ of the remaining uncovered selements, i.e., $\\frac{c_i}{k}$. Otherwise, it was impossible to\ncover $OPT$ many elements at $k$ steps by the optimal solution. Since the approximation algorithm is greedy, i.e., choosing always the set\ncovering maximum number of uncovered elements, the chose set at each iteration should be atleast the $\\frac{1}{k}$ of the remaining uncovered\nelements. That is $a_{i+1} \\geq \\frac{c_i}{k}$.\n\n**Lemma 2.** $c_{i+1} \\leq (1-\\frac{1}{k})^{i+1}.OPT$\n\n*Proof*. We will prove by induction. Let us first show that the claim is true for  $i=0$.\n\n$\nc_1 \\leq (1-\\frac{1}{k}).OPT\n$\n\n$\nc_1 \\leq OPT-OPT.\\frac{1}{k}\n$\n\n$\nOPT - b_1 \\leq OPT-OPT.\\frac{1}{k} \\space (\\text{since } c_1 = OPT - b_1)\n$\n\n$\n-b_1 \\leq -OPT.\\frac{1}{k} \\space (OPT\\text{'s cancels each other})\n$\n\n$\nb_1 \\geq OPT.\\frac{1}{k}\n$\n\n$\na_1 \\geq OPT.\\frac{1}{k} \\space (\\text{since } b_1 = a_1)\n$\n\n$\na_1 \\geq c_0;\\frac{1}{k} \\space (\\text{since } c_0 = OPT \\text{ by our initial assumptions})\n$\n\n&nbsp;\n\nBy lemma 1, we actually know that $a_1 \\geq c_0.\\frac{1}{k}$. Hence, the proof for $i=0$ follows. Now, for the inductive hypothesis\nassume $c_i \\leq (1-\\frac{1}{k})^i$. $OPT$ is true, and show that $c_{i+1} \\leq (1-\\frac{1}{k})^{i+1}$. $OPT$ is true.\n\n$\nc_{i+1} = c_i - a_{i+1} \\space (\\text{by definition of } c_i = OPT - \\sum_{j=1}^{i}a_j)\n$\n\n$\nc_{i+1} \\leq c_i - \\frac{c_i}{k} \\space (\\text{by lemma 1})\n$\n\n$\nc_{i+1} \\leq c_i(1- \\frac{1}{k})\n$\n\n$\nc_{i+1} \\leq (1-\\frac{1}{k})^i.OPT.(i-\\frac{1}{k}) \\space (\\text{by inductive hypothesis})\n$\n\n$\nc_{i+1} \\leq (1-\\frac{1}{k})^{i+1}.OPT\n$\n\n&nbsp;\n\nHaving proved the lemma 1 and 2, now we are ready to prove the approximation factor for greedy algorithm for maximum coverage problem.\n\n**Theorem.** *Greedy approximation algorithm has $(1-\\frac{1}{e})$ approximation factor.*\n\n*Proof.* By lemma 2, we know that $c_k \\leq (1-\\frac{1}{k})^k.OPT$. Since $(1-\\frac{1}{k})^k \\approx \\frac{1}{e}$, we can say that\n$c_k \\leq \\frac{OPT}{e}$. Then,\n\n$\nb_k = OPT - c_k \\space (\\text{by definition})\n$\n\n$\nb_k = OPT - \\frac{OPT}{e}\n$\n\n$\nb_k = OPT(1-\\frac{1}{e})\n$\n\nSince $b_k = \\sum_{j=1}^ka_j$, i.e., the total number covered elements after the $k^{th}$ iteration which is the output of the greedy algorithm,\nwe can conclude that the greedy approximation has $(1-\\frac{1}{e})$ approximation factor.\n\nAnd hence, this greedy apprpximation is a nice way to solve the maximum coverage problem. Now let us apply this idea to the game of Guess Who?\n    ",application1:'\nWe\'re finally here! \ud83d\ude4c\n\n### **Features as Sets**\n\nThe "sets" that we will consider in Guess Who? are nothing but the facial features of the characters. We can name the sets according to the\ncorresponding features. For example: *Only Bald, Bald with Glasses, Red Hair, Hat and Facial Hair, etc..*\n\nConsider Sam for example:\n\n    ',application2:"\nThis character would be part of the *Bald with Glasses* set. It is evident that many sets will have overalapping elements, just like in the\nMaximum Coverage Problem.\n\n### **The Pseudocode**\n\nThe input `k` that we will be using here (number of moves in which we have to win to maximize our chances) is 5 for reasons described above.\n\nLet\n\n`F_x` is the feature set corresponding to some feature `x`\n\n`U` be the set of all feature sets, i.e. `U` = {`F_redHair`, `F_glasses`, `F_rosyCheeks`, etc.}.\n\nLet `|F_x|` denote the number of elements in set `F_x`.\n\nLet `k` denote the number of moves we should perform to win which is 5 as described above.\n\nEach character can be represented as a bit-vector along with a string, with each position in the vector corresponding to some feature. \nA 1 in a position means that that character does have that feature and 0 means that that character doesn't have said feature. The last\nposition of the bit-vector is reserved for a special purpose. It is set to 1 if that character is possibly the character the opponent is\nthinking of, and it is 0 if that character has been eliminated. We'll call it the flag. The name of the character is stored in the string.\n\n```\nk = 5\nInput: Array of 24 characters.\nInput: SC = Your secret character.\nChar_Count = 24\nWin_Flag = 0\n\nwhile k > 0:\n    for every feature set F:\n        remove all elements from F\n    for every character C:\n        if C.flag == 1:\n            for every feature set F:\n                if C has feature corresponding to F:\n                    Insert C into F\n    \n    Max = -1\n    Chosen_Set = none\n    for every feature set F:\n        if |F| > Max:\n            Max = |F|\n            Chosen_Set = F\n    \n    Make Guess with the feature corresponding to Chosen_Set\n    Response = Get Response\n\n    if Response == YES:\n        for every feature set F:\n            if F != Chosen_Set: \n                for every character C in F:\n                    C.flag = 0\n                \n        for every character C in Chosen_Set:\n            C.flag = 1\n        Char_Count = Max\n\n    else:\n        for every character C in Chosen_Set:\n            C.flag = 0\n        Char_Count = Char_Count - Max\n\n    if Char_Count == 1:\n        for every character C:\n            if C.flag==1:\n                Make guess C\n        Win_Flag = 1\n    \n    Let opponent's turn play out.\n    Let x = Opponent's guess\n\n    if x == SC:\n        if Win_Flag == 0:\n            The opponent Wins. Terminate Algorithm.\n        else:\n            It is a draw. Terminate Algorithm.\n    else if Win_Flag == 1:\n        You win. Terminate Algorithm.\n```\n\nIt is important to realize here that the game logic itself is quite trivial. The really important part is to identify features\nthat will lead to optimal size feature sets. Also, this is not an \"Always Win\" algorithm as there is always a chance for the\nopponent to get really lucky with their guesses. Rather, this is an approach with a definitive mean.\n    ",spicyMath1:'\n### **Strategy**\n\nBefore laying out the optimal strategy, it would be beneficial for us to define some variable and terms which will be used in the strategy\nand further in this discussion:\n\n* **$n$** is the number of candidates in the Player 1\'s pool.\n* **$m$** is the number of candidates in the Player 2\'s pool.\n* A **$\\text{Bid}$** of side $b$ refers to a player asking a question such that if the answer to the question is "Yes" then the size of the pool\nof the candidates for the player who asked the question becomes $b$ and if the answer is "No", then then the size of the pool becomes\n$n-b$ for the first player or $m-b$ for the second player.\n\nThe obvious strategy, that first came to my mind was of that to choose $$b = \\lfloor \\frac{n}{2} \\rfloor $$.  This is not the optimal strategy in \u201cGuess Who?\u201d because Player 1 does\nnot want to minimize this expected value: instead he wants to maximize the probability of getting there before Player 2 does. This race against the opponent is what drives the optimal bidding behavior when\nPlayer 1 is significantly behind his opponent.\n\nLets gets get into the crux: **The strategy**.\n\nWhen it is Player 1\'s turn, if Player 1 has $n$ candidates in their pool and Player 2 has $m$ candidates in their pool, then Player 1 has the\nfollowing optimal strategy:\n\n* If $n \\geq 2^{k+1} + 1$ while $2^k+1 \\leq m \\leq 2^{k+1}$ for some $k \\in \\mathbb{N} \\cup 0$, then Player 1 is in the weeds and must gamble \non a risky move to catch up. Their optimal play is a bid of\n\n$$\nb^*(n, m) = 2^k = 2^{\\log_2(m-1)}\n$$\n\nand the probability Player 1 wins if both players play optimally is:\n\n$$\np^*(n, m) = \\frac{2^{k+1}}{n} - \\frac{2}{3} \\times \\frac{2^{2k+1}+1}{nm} \n$$\n\n* If $2^k+1 \\leq n \\leq 2^{k+1}$ while $m \\geq 2^{k+1}$ for some $k \\in \\mathbb{N} \\cup 0$ then Player 1 has the upper hand and can stay in the\nlead by making low risk, sure-shot plays. Their optimal bid is\n\n$$\nb^*(n, m) = \\lfloor\\frac{1}{2}n\\rfloor\n$$\n\nand the probability that Player 1 can win if both the players play optimally is:\n\n$$\np^*(n, m) = 1 - \\frac{2^k}{m} + \\frac{2}{3} \\times \\frac{2^{2k} + 2}{nm}\n$$\n\nThe winning probability for player 1 based on the size of the pool of candidates of player 1 vs player 2 from any situation is plotted as follows:\n    ',spicyMath2:'\n### **The Mathematical Model**\n\nThe first step to finding the optimal strategy is to fist convert the game into a mathematical model. To do this, we\nmake one simple assumption:\n\n*The secret identity of the opponent is uniformly distributed amongst all possible candidates. Because of the eliminating nature of \nthe \u201cYes\u201d/\u201cNo\u201d questions, this property persists throughout the game. With this assumption, only the number of remaining characters \nin the pool is relevant to the analysis, not the details of which characters in particular are remaining.*\n\nWith this assumption we can mode the game as a **Simple Stochastic Game**.\n\n*In game theory, a stochastic game, introduced by Lloyd Shapley in the early 1950s, is a dynamic game with probabilistic transitions \nplayed by one or more players. The game is played in a sequence of stages. At the beginning of each stage the game is in some state. \nThe players select actions and each player receives a payoff that depends on the current state and the chosen actions. The game then \nmoves to a new random state whose distribution depends on the previous state and the actions chosen by the players. The procedure is\nrepeated at the new state and play continues for a finite or infinite number of stages. The total payoff to a player is often taken\nto be the discounted sum of the stage payoffs or the limit inferior of the averages of the stage payoffs.*\n\nWe\'ll model the agme into the followinf statespace:\n$$\nS=\\{\\langle n,m,P_i\\rangle: n,m \\in \\mathbb{N} , i \\in \\{1,2\\}\\}\n$$\n\nThe first entry $n$  indicates the size of the pool of candidates player 1 is left with and the second entry $m$ indicates the size of\nthe pool of candidates player 2 is left with. The last token tells which player has to take its turn.\n\nSuppose the value of last token is $P_1$. This means that player 1 takes his turn. He will ask a "Yes"/"No" question from player 2 \nregarding his character\'s secret identity, and based on the answer lets consider $b_1$ the size of pool left if the answer is "Yes". \nThis is called Player 1 making a bid of $b_1$ Thus the next state would be something like this:\n$$\n\n\\text{Starting at }\\langle n,m,P_1 \\rangle \\text{ with Player 1 bidding }b_1\\longrightarrow \n\\begin{cases}\n\\langle b_1,m,P_2 \\rangle & \\text{with probability } \\frac{b_1}{n} \\\\\n\\langle n-b_1,m,P_2 \\rangle & \\text{with probability } \\frac{n-b_1}{n}\n\\end{cases}\n$$\n\nThis type of play continues till one of the players is left with size of pool = 1. That is to say the following states are terminal states \n\n$$\n\\forall m>1,\\langle 1,m,P_2 \\rangle \\leftrightarrow \\text{Player 1 immediately wins} \n$$\n\n$$\n\\forall n>1, \\langle n,1,P_1 \\rangle \\leftrightarrow \\text{Player 2 immediately wins}\n$$\n\nThe state $\\langle 1,1,P_i \\rangle$ is not possible because before the other player reaches 1 the player which had already reached that \nstate would declare the win.\n\nThis definition of the game puts it under the framework of *Simple Stochastic game.* \n\nThe *Simple Stochastic Game* show the existence of an optimal bidding strategy. The bidding for this strategy can be denoted as:\n\n$$\nb^* : \\mathbb{N} \\times \\mathbb{N} \\rightarrow \\mathbb{N}\n$$\n\nand the optimal probability function can be denoted by \n\n$$\np^* : \\mathbb{N} \\times \\mathbb{N} \\rightarrow [0,1]\n$$\n\nthat is optimal for Player 1 in the sense that:\n\n* If Player 1 makes the bid $b^* : \\mathbb{N} \\times \\mathbb{N} \\rightarrow \\mathbb{N}$ when the state is $\\langle n,m,P_1\\rangle$ \nthen no matter the strategy Player 1\'s probability of winning is $ \\geq p^*: \\mathbb{N} \\times \\mathbb{N} \\rightarrow [0,1]$.\n* If Player 1 makes some other bid then the probability is $\\leq p^*$.\n\nThe game guess who is symmetric between Player 1 and Player 2 in the sense that the position $\\langle n,m,P_1\\rangle$ is functionally \nidentical too $\\langle m,n,P_2\\rangle$. This means that if the probability for player 1 to win is $p^*(n,m)$ then probability for \nplayer 2 is $p^*(m,n)$. Because of this symmetry, the optimal probability function satisfies a nice recurrence relation:\n\n$\n\\textbf{Proposition: } p^*(n,m) \\text{ and } b^*(n,m) \\text{ satisfy the following recurrence}\n$\n\n$$\np^*(m,n)=\\max_{b \\in[1,n-1] } \\{ 1-\\frac{b}{n}p^*(m,b)-\\frac{n-b}{n}p^*(m,n-b) \\}\n$$\n\n$$\nb^*(m,n)=\\arg \\max_{b \\in[1,n-1] } \\{ 1-\\frac{b}{n}p^*(m,b)-\\frac{n-b}{n}p^*(m,n-b) \\}\n$$\n\n$\n\\textit{Proof}\n$\n\nLet $p_b(n,m)$ be the probability that player 1 wins from the position $\\langle n,m,P_1 \\rangle if he bids \\text{b} at \\langle n,m,P_1 \\rangle$ \nand both players play optimally thereafter. By the rules of the game then\n\n$$\np_b(n,m) = \\frac{b}{n}(1-p^*(m,n)) + \\frac{n-b}{n}(1-p^*(m,n-b))\n$$\n\nsince with probability $\\frac{b}{n}$ we move to the position $\\langle b,m,P_2 \\rangle$ where Player 1\'s probability to win is $1-p*(m,n)$ and \nwith the probability $\\frac{n-b}{n}$ we move to the position $\\langle n-b,m,P_2 \\rangle$where Player 1\'s probability of win is $1-p^*(m,n-b)$.\n\nThe following is the psuedo code for finding the $p^* \\text{ and } b^*$\n\n**Algorithm 1** Numerically computing $p^*(n,m)$ and $b^*(n,m)$\n    ',spicyMath3:"\nNow we are going to divide our statespace into two different sets which are namely **In the weeds** and **the upper hand**.\n\n#### **In the Weeds**\n\n$$\nW_{k,P_1} := \\{\\langle n,m,P_1\\rangle : 2^{k+1} < n \\text{ and } 2^k < m \\leq 2^{k+1}\\} \n$$\n\nWhen $\\langle n,m,P_1 \\rangle \\in W_{k,P_1}$ we say that Player 1 is in the weeds at level $k$.\n\n#### **The Upper Hand**\n\n$$\nU_{k,P_1} := \\{\\langle n,m,P_1 \\rangle: 2^k < n \\leq 2^{k+1} \\text{ and } 2^k < m \\} \n$$\n\nWhen $\\langle n,m,P_1 \\rangle \\in U_{k,P_2}$ we say that Player 1 has the Upper hand at level $k$.\n\n## Proof time\n\nFunction $q(n,m)$ is used to find the probability for player 1 winning at a certain state and can be split in the following way.\n    ",resource:"\n- **Optimal Strategy in \u201cGuess Who?\u201d: Beyond Binary Search - Mihai Nica**\n- Lectures on Complexity by Jhonathan Katz\n- Article on pipmodern about Complexity State of game space Tree\n- Video by Mark Rober on Guess Who\n- Article by Chalkdust Magazine on cracking board Games\n- **Condon, A. (1992). The complexity of stochastic games**. Information and Computation 96, 203\u2013224\n    "},ee={fontFamily:"AudioWide",fontSize:"2rem"},te={inlineMath:function(e){var t=e.value;return Object(s.jsx)(M.InlineMath,{math:t})},math:function(e){var t=e.value;return Object(s.jsx)(M.BlockMath,{math:t})}},ne=Object(s.jsx)("div",{className:"my-4 py-2"}),se=function(){return Object(s.jsxs)(s.Fragment,{children:[Object(s.jsx)(E,{}),Object(s.jsxs)("div",{className:"d-flex-column align-items-end mt-3 p-0",style:{fontFamily:"Oswald",marginLeft:window.innerWidth>991?"5rem":"0.5rem"},children:[Object(s.jsx)("h1",{className:"text-center",style:{fontSize:"3rem",fontFamily:"AudioWide"},children:"GUESS WHO?"}),Object(s.jsx)("hr",{className:"mb-5"}),Object(s.jsxs)("div",{className:"container mb-5",style:{fontSize:"1.3rem"},children:[Object(s.jsx)("h2",{style:ee,children:"\ud83d\udcdc INTRODUCTION AND RULES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:Q.introAndRules1}),ne,Object(s.jsx)("h2",{style:ee,children:"\ud83d\udc40 A QUICK ANALYSIS"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:Q.quickAnalysis1}),Object(s.jsx)(W.a,{source:Q.quickAnalysis2}),ne,Object(s.jsx)("h2",{style:ee,children:"\ud83e\udd3f A DEEPER DIVE"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:Q.deeperDive1,plugins:[B.a],renderers:te}),Object(s.jsx)("div",{className:"row justify-content-center mb-5",children:Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/1.png",alt:"Distribution",className:"img-fluid col-12 col-md-8"})}),Object(s.jsx)(W.a,{source:Q.deeperDive2,plugins:[B.a],renderers:te}),ne,Object(s.jsx)("h2",{style:ee,children:"\u2699\ufe0f GETTING TECHNICAL: THE MAXIMUM COVERAGE PROBLEM"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:Q.maximumCoverageProblem,plugins:[B.a],renderers:te}),ne,Object(s.jsx)("h2",{style:ee,children:"\u2728 APPLYING THE THEORY"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:Q.application1,plugins:[B.a],renderers:te}),Object(s.jsx)("div",{className:"row justify-content-center mb-5",children:Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/2.png",alt:"Sam",className:"img-fluid col-6 col-md-3"})}),Object(s.jsx)(W.a,{source:Q.application2,plugins:[B.a],renderers:te}),ne,Object(s.jsx)("h2",{style:ee,children:"\ud83c\udf36\ufe0f SOME SPICY MATH"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:Q.spicyMath1,plugins:[B.a],renderers:te}),Object(s.jsx)("div",{className:"row justify-content-center mb-5",children:Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/3.png",alt:"Probability",className:"img-fluid col-12 col-md-10"})}),Object(s.jsx)(W.a,{source:Q.spicyMath2,plugins:[B.a],renderers:te}),Object(s.jsx)("div",{className:"row justify-content-center mb-5",children:Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/4.png",alt:"Algorithm",className:"img-fluid col-12"})}),Object(s.jsx)(W.a,{source:Q.spicyMath3,plugins:[B.a],renderers:te}),Object(s.jsxs)("div",{className:"row justify-content-center mb-5",children:[Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/5.png",alt:"Algorithm",className:"img-fluid col-11 col-md-6"}),Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/6.png",alt:"Algorithm",className:"img-fluid col-12"}),Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/7.png",alt:"Algorithm",className:"img-fluid col-12"}),Object(s.jsx)("img",{src:"/assets/ContentImages/GuessWho/8.png",alt:"Algorithm",className:"img-fluid col-12"})]}),ne,Object(s.jsx)("h2",{style:ee,children:"\ud83d\udcdd REFERENCES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:Q.resource}),Object(s.jsx)("hr",{className:"mb-1"}),Object(s.jsx)("h1",{className:"display-1 text-center",children:"\u2753"})]})]})]})},ae={intro:"\nScotland yard is a popular board game, named after Scotland Yard, the headquarters of London's Metropolitan Police Service. It is played \nby 2-6 players in which one of the players is the criminal (Mr. X) and the remaining are detectives. As is intuitive, *the objective of the \ngame for the detectives is to catch the criminal, while the objective of the criminal is to run away from its pursuers for 22 rounds*. \n**It is an asymmetric board game since the players do not have the same goal**. \n    ",rule1:"\nLet's take a look at the rules once, before we jump into analysing the game.\n\n#### **Movement of players**:\n\nEach detective and the criminal is assigned a pawn to mark their position on the board. There are a **total of 199 positions on the Scotland Yard \nboard**. Each *position can represent 1-3 stations, a taxi, a bus, and an underground route*, which is marked by a number and the colour of \nthe station it represents.\n\n**Every station on the map can be reached with the taxi** (*yellow*). However, the distance that you can travel is short: \nYou can only move (along the yellow line) to the next station.\n\nThe\xa0bus (*turquoise*) **only drives from stations with a turquoise semi-circle**; a bus will take you a little further than the taxi (along the bus line).\n\nThe\xa0underground\xa0(*red*) **travels along the red line and covers the furthest distances the quickest**. However, there are only a few underground \nstations (stations with a red inner rectangle) on the map.\n\nAll playing pieces can only be moved to unoccupied stations. **If there are no unoccupied stations for Mister X to travel to, he has lost \nthe game. Mister X also loses if one of the detectives moves to the station where Mister X is located**.\n    ",rule2:"\n#### **Tickets :**\n\nEach detective receives ticket cards that allow him to across the board. At the start of the game, each detective gets `4 underground tickets, \n8 bus tickets, and 11 taxi tickets, and each detective receives 5 black tickets and 2 double move tickets`.\n\nIn each round, after **a detective** has used up a ticket to travel to another position, **they cannot use them again**, however, this *ticket is now available \nfor Mr. X's use*. If a detective no longer has any tickets or can't move from his current station with the tickets he has left, they have to sit out.\n\nA black ticket allows Mr.X to hide the route he used and also travel by ferry (a route only he is allowed), and a double move ticket allows him to make two \nmoves to two different stations in one round.\n\n#### **Initial Starting Position:**\n\nTo determine each player\u2019s starting position, a set of start cards marked D and X are shuffled separately and each detective selects from the D cards and \nplaces their playing piece on the respective position. Mr. X picks an X card but doesn\u2019t reveal his position to the detectives or place his playing piece on the board.\n\n#### **Game Play:**\n\nIn total, **22 rounds are played**. In each round, *Mr. X first makes their move, concealing his new position from the remaining players*, and \nwrites down the station he moved to on a paper, hiding the station with the ticket they used. (The detectives can see which mode of transport Mr.X has used.)\n\nWhen a detective makes a move, the used-up ticket is placed in the general draw pile where Mr. X gets his tickets (**so Mr. X basically has an unlimited number of tickets**).\n\n#### **Moving Mr.X:**\n\nEach turn Mr. X conceals his move. However, there are **special moves** (`3rd, 8th,13th, 18th, and 24th moves`) where Mr. X **must surface**. He has to reveal his current position \nbefore moving to a new station, which gives detectives the chance to co-ordinate and corner the criminal!\n\n#### **Moving the Detectives:**\n\nThe detectives use their tickets to move around the board. *If they run out of tickets or don't have the required ticket to move out of a station, they must \nsit out of the game*. Detectives can't trade tickets among themselves and all their remaining tickets have to be visible to Mr. X, so he can see the remaining means of transportation they have left.\n\n#### **Winning The Game**\n\nMr. X wins if - \n\n- He is able to move around the board for 22 rounds without being caught.\n\nThe detectives win if - \n\n- They corner Mr. X (he has no stations to go to where a detective is not present)\n- They move to a station where Mr. X is currently\n\nNow that we understand how to play, let's dive into different aspects of the game!\n    ",obj:"\nThe goal of this page is to analyze the game Scotland Yard. \n\nWe start off by venturing into proofs for **Scotland Yard being a PSPACE problem and the similarities between Scotland Yard and a game of \nperfect information**. It is easy to feel daunted by these claims, `trust me we felt it too`. *To make it easier, we remove all the layers of \nabstraction from the game first. We convert the game into a problem of Groups, Graphs, and Sets*. \n\nIt is understandable if you think it still is going to be tough. We ensure that you will understand what these jargons are and how they interact with the \ngame itself. We firstly introduce Games with the viewpoint of perfect and imperfect information. Then we connect Scotland Yard to that idea and \nremove all the layers of abstraction. Once that is done, we proceed with proofs. \n\nWe then explore some heuristic approaches - strategies that you might tend to use after playing the game a few times. These are \nunproven methods, but after some experience, arise as the best way to win, either as detectives or as Mr. X.\n    ",foundation:"\nTo properly explain some concepts, we need to define some terms: \n\n**Extensive Games:** Games that allow the representation of various key aspects. These aspects include a set of players, each player's moves, \ntheir decisions, the information (possibly imperfect) about a player, and their payoffs for all possible outcomes. Essentially, they are \ngames that can be represented with a game (decision) tree.\n\n**Perfect Information Game:** In a perfect information game, a player has complete information about all events which have previously occurred in the game.\n\n**Imperfect Information Game:** Games which have some aspects of the game hidden are called imperfect information game. \n\nIt is easily understandable why Scotland Yard comes under the bracket of the extensive game with imperfect information. For it to be an extensive \ngame, it should formally represent each and every aspect of the game, which is the moves and mode of commutation each player uses. Even if the moves are \nhidden, they are definite and are represented. Since the moves are hidden, it is impossible for the detectives to know which route the criminal has \ntaken, which makes it an imperfect information game. \n\nNow, let's look into some abstraction or representations. \n\nAny win-loss game $G$ with perfect information can be represented as a 4-tuple\n\n$$\n\\text{G} \\space = \\space <N, H, P, U>\n$$\n\n- **$N$:** Represents the number of total players. \n\n- **$H$:** Is a set of histories. A history ($h$) represents a given state of the board at some point in time. Every $h$ = $<a_1, a_2 . . . a_p>$ , where \n$a_i$ is an action. Each history is an ordered list of actions. \n- $h'$ = <$h$, $a'$> represents the immediate successor of $h$, where $h'$ = $< a_1, a_2 . . . a_p, a'>$. There are two types of history, terminal ($Z$) and \nnon-terminal ($H-Z$). Terminal represents an end condition, after which no other action can be taken. A history becomes terminal when a player wins. \n\n- **$P$:** Is the player function. It assigns to each non-terminal history a particular player. Formally, we define it as $P: \\{H - Z\\} \\rightarrow N$. \nWe say that a history $h$  belongs to $P(h)$, essentially when the last action in the set of actions that is $h$ is made by the player.\n\n- $U:$  Is the utility function, assigning each terminal history to a player. (the player has won the game). The formal definition would be $U: Z \\rightarrow N$.\n\nGiven $G$  defined as above, a function $S$ is called a strategy for a player  $\\space i \\in N$ if it maps for every history $h$  belonging to $i$ to an action $A(h)$. \n\nAn extensive game with imperfect information extends a game with perfect information. To represent the former, all you need is to add is an \nInformation function in the original tuple.\n\n$$\n\\text{G} = \\space < N, H, P, {\\langle\\mathcal{I}_i\\rangle}_{i\\in N}, U>\n$$\n\nThe only difference in this is that  $\\mathcal{I}_i$ carries information sets for each $i \\in N$. $\\space \\mathcal{I}_i = \\{I_1, I_2, . . . Iq\\}$ \nwhere each $I$ represents a set of histories, there having been $q$ rounds of the game played so far. Each $I$ basically is a set \nof histories (or state changes of the board) of that round (till $i$ makes an action again).  Intuitively, an extensive game \nwith imperfect information models the situation in which player $i$ knows that some history $h \\in I \\in \\mathcal{I}_i$  has happened, but there \nare unable to tell $h$  apart from the other histories in $I$. In simple terms, they know other players have made a move based on the last action \nthey took, but are not completely sure of the previous actions the player took. \n\nA function $S$  is called a strategy for a player $i$  in $\\text{G}$ if it maps every information partition $I \\in \\mathcal{I}_i$ belonging to $i$ onto action in $A(I)$\n\n### **Assumptions for Mathematical Modelling**\nFor convenience, there are some assumptions which have been taken.\n\n1. **There is only 1 mode of transport**, that is Taxi. The same method described as follows can be easily translated with more modes of transport.\n2. A player will have $k$ amount of tickets of Taxi, where $k$ = number of rounds.\n3. There are only two players, Detective and Mr X.\n4. *Only 1 player will be controlling all detectives.*\n5. Value of $k$ will be always $\\leq |V|$, where $V$ is the number of nodes in the graph.\n6. We have used digraph to represent the game board.\n7. **Mr. X will always play the first move in each round**.\n8. *Mr. X will be considered to be caught IF AND IF ONLY it is on a node occupied by a detective at the END of the round (after detectives have moved)*.\n9. Mr X will win if and if only the game goes on for $> k$ rounds, otherwise Detectives have won.\n    ",formal1:"\nWe now *know how to formalise any given perfect or imperfect information game*. Now let's connect it to the game Scotland Yard. \n\nLet $SY$ = $\\langle G, \\langle u_*, \\overrightarrow{v_{*}}\\rangle, f\\rangle$  be a Scotland Yard instance. Then, let the extensive \nScotland Yard game constitute by $\\mathcal{SY}$ be defined as the tuple \n\n$$\n\\mathcal{SY}(\\text{SY}) = \\langle N, H, P, \\bullet, U\\rangle\n$$\n\nHere, \n\n- $G$ represents a digraph.\n- $u_*$ represents the position of Mr X.\n- $\\overrightarrow{v_*}$  is $n$ dimensional vector, where n is the number of detectives. Each element in the vector represents the initial node of the detective.\n- $f$ is a function which when fed a number (no. of rounds) chooses one of the two elements from the set $\\{ show, hide\\}$ . This denotes whether \nMr X needs to show their position or not.\n- $N$ represents total number of players. For convenience, $N = \\{ \\forall, \\exists \\}$ where $\\forall$ represents Mr X and $\\exists_1, \n\\exists_2 . . \\exists_{N-1}$ represent the detectives.\n- $H$ represents a set of histories.  Let $\\prec$ be the immediate successor relation on $H$ . So you can say that $\\langle h \\rangle \\prec \\langle h, u \\rangle$  \nwhere $\\langle h \\rangle, \\langle h, u\\rangle \\in H$\n- $P$ represents the player function. Due to notational convenience, it is easy to assign the value of the player function.  \n$P( \\langle h, u \\rangle ) = \\forall$  and $P(\\langle h, u , \\overrightarrow{v} \\rangle ) = \\exists$ no matter $u$  or $\\overrightarrow{v}$.\n- $\\bullet$  is the indistinguishability relation. It is defined on the group $H$. For any two histories  $h, h' \\in H$ , where the length of both histories is equal, $h \\bullet h'$ when:\n\nIf $h = \\langle u_* , \\overrightarrow{v_*}, u_1, \\overrightarrow{v_1}, . . . u_i, \\overrightarrow{v_i} \\rangle$ and $h' = \\langle u_* , \\overrightarrow{v_*}, u'_1, \\overrightarrow{v'_1}, . . . u'_i, \\overrightarrow{v'_i} \\rangle$ then\n\n1. $\\overrightarrow{v_j} = \\overrightarrow{v'_j} \\space \\forall \\space 1 \\leq j \\leq i\\ $ and\n2. $u_j = u'_j \\space \\forall \\space 1 \\leq j \\leq 1$   such that  $f(j)  = show$ \n- $U: Z \\rightarrow \\{win, lose\\}$  is the utility function which determines whether $\\exists$ won or not.\n\n$$\nU(\\langle h, u, \\overrightarrow{v} \\rangle) = \n\\begin{cases}\nwin, \\space \\space u\\in \\overrightarrow{v} \\\\\nlose, \\space \\space u \\notin \\overrightarrow{v}\n\\end{cases}\n$$\n\nIt is easy to see that the operation $\\bullet$  is Equivalent to the group $H$. We write $\\mathcal{H} \\subseteq \\wp(H)$ for the set of \nequivalent classes, or information cells, in which $H$ is partitioned by $\\bullet$ . \n\n$\\mathcal{H} = \\{ C_1, C_2 . . . C_n\\}$, where $H = C_1 \\cup C_2 . . \\cup C_m$ for every $1 \\leq i \\leq m$ , if $h \\bullet h'$  where $h, h' \\in C_i$.  \n\nWe lift the relation $\\prec$  to $H$, using the same symbol: For any pair $C, C' \\in H$, we write $C \\prec C'$ if there exists histories $h \\in C$ and $h' \\in C'$ such that $h \\prec h'$. \n\nWe can also extend this as if $h, h' \\in C$  and $C \\in H$, then $P(h) = P(h')$. Thus the player function is meaningfully lifted as follows: if $C \\in H$ and $h \\in C$, then $P(C) = P(h)$.\n    ",formal2:"\nConsider an example game $G^x$ . Let $f^x$ be the information function where $f^x(1) = hide$ and $f^x(2) = show$. Let $u_*$ and $v_*$ as the initial position \nof $\\forall$ and $\\exists$ . Consider that number of detectives to be 1. Let's play this game.\n\n The set of histories we can get from this game are:\n    ",formal3:"\nwhere ! marks terminal histories. To reflect that this is a game of imperfect information, we can write \\mathcal{H} as\n    ",formal4:"\nA graphical representation of this would be: \n    ",formal5:"\n#### **Perfect Information Scotland Yard**\nSo, Perfect Information means that each and every aspect of the game is explicitly expressible. The only difference we need to model here is \n$\\forall$'s whereabouts. Since describing each position will convert Scotland Yard into a simple game of Cops and Thieves, we don't do that. \nInstead, to preserve the game, we describe the position of $\\forall$ as a set of possible nodes.\n\nMore abstractly, \u2200\u2019s powers are lifted from the level of picking up vertices to the level of picking up sets of vertices. \u2203\u2019s powers remain unaltered, as compared to \nthe game with imperfect information that was explicated above. It is defined as:\n\n$$\n\\mathcal{SY-PI}(SY) : \\langle N_{PI}, H_{PI}, P_{PI}, U_{PI} \\rangle \n$$\n\nThe above mentioned example will be converted to\n    ",formal6:"\n#### **Effective Equivalence**\nIn this section, we establish that $\\exists$ has a winning strategy in $\\mathcal{SY}(SY)$ iff it has a winning strategy in $\\mathcal{SY-PI}(SY)$. \nIn order to prove this, it will be shown that $\\langle H, \\prec \\rangle$  is isomorphic to $\\langle H_{PI}, \\prec_{PI} \\rangle$ in virtue of the bijection $\\beta$\n\nThe function $\\beta$ is a map from histories in the perfect information game $\\mathcal{SY-PI}(SY)$ to information cells in the game $\\mathcal{SY}$. \nTo formally define it, $\\beta: H_{PI} \\rightarrow \\wp(H)$.\n\nFor example, in the above mention $G^X$, we will map $\\beta(\\langle u_*, v_*, u_1 \\rangle)$ where $u_1 = \\{a, b\\}$ to $C_1$ where \n$C_1 = \\{\\langle u_*, v_* , a\\rangle , \\langle u_*, v_*, b \\rangle \\}$\n\nJust as a reminder, $C_i$ represents an indistinguishable state for $\\exists$ in $\\mathcal{SY}(SY)$.\n\nThe perfect information Scotland Yard game was defined in such a way that $\\exists$'s imperfect\ninformation in $\\mathcal{SY}(SY)$ is propagated to perfect information about sets in $\\mathcal{SY-PI}(SY)$.\n\nExample of $\\beta$ in lieu of above mentioned example would be:\n    ",formal7:"\nIt is important to note that though here $\\beta$ is defined to have a codomain $\\wp(H)$, it ends up having a range of $\\mathcal{H}$. This is due to \nthe output always being $C_i$ and $\\mathcal{H} = \\{C_1, C_2 . . C_m \\}$. \n\nTo better define $\\beta$ and actually make it bijective, we redefine it as\n\n$$\\beta: H_{PI} \\rightarrow \\mathcal{H}$$\n\nNow, let's prove that the groups $\\langle H, \\prec \\rangle$  and $\\langle H_{PI}, \\prec_{PI} \\rangle$  are isomorphic. \n\nIt is proved that $\\beta$ is a bijection between $H_{PI}$ and $\\mathcal{H}$. It remains to be shown that $\\beta$ preserves structure. \n\nRecall that for $C' \\in \\mathcal{H}$  to be an immediate successor of $C \\in \\mathcal{H}$, there must exist two histories $g, g'$ in $C, C'$ \nrespectively such that $g \\prec g'$ (Proved earlier).\n\nWhat this proves is that for any histories $h, h' \\in H_{PI}$ it is the case that $h \\prec_{PI} h'$ iff $\\beta(h) \\prec \\beta(h')$. \n\nThe claim is proved by a straightforward inductive argument on the length of the histories in\n$H_{PI}$\n\nMaking use of the fact that $\\langle H_{PI}, \\prec_{PI} \\rangle$  and $\\langle H, \\prec \\rangle$ are isomorphic groups, an inductive argument \nproves that $S$ is a winning strategy for $\\exists$  in $\\mathcal{SY-PI}$ iff $S(\\beta)$ is a winning strategy for $\\exists$ in $\\mathcal{SY}(SY)$.\n    ",pspace:"\nLet $\\text{SCOTLAND YARD}$ be the set of all Scotland Yard instances such that  $\\exists$  has a winning strategy in $\\mathcal{SY}(SY)$\n\nIf we are able to prove that there is a winning strategy in PSPACE for $\\mathcal{SY}(SY)$, then it will stand true for $\\mathcal{SY-PI}(SY)$ as well.\n\nPapadimitriou, namely, observed that deciding the value of a game with perfect information can be done in PSPACE if the following requirements are met:\n\n- The length of any legal sequence of moves is bounded by a polynomial in the size of the input\n- Given a \u201cboard position\u201d of the game there is a polynomial-space algorithm which constructs all possible subsequent actions and board \npositions; or, if there aren\u2019t any, decides whether the board position is a win for either player.\n\n$\\mathcal{SY-PI}(SY)$ meets those condition. \n\nFor the first point, the length of the description of any history is bounded by the number of rounds $k$, of the game. By \nassumption, $k \\leq |V|$, thus it is polynomially bounded. \n\nFor the second point, as we have seen till now, each board game can be represented in form of a decision tree. More formally, \nif $\\langle h, U, \\overrightarrow{v} \\rangle$ is a non terminal history, then its successors are \neither (depending on $f$) m only $\\langle h, U, \\overrightarrow{v}, \\{w_1 ,. . ., w_m \\} \\rangle$ or \nall of $\\langle h, U, \\overrightarrow{v}, \\{ w_1 \\} \\rangle$ , . . . , $\\langle h, U, \\overrightarrow{v}, \\{ w_m \\} \\rangle$ \n\nWhere $E(U-\\{\\overrightarrow{v}\\}) = \\{ w_1, w_2 , . . , w_m\\}$. These can easily be constructed in PSPACE.\n\nHENCE PROVED $\\mathcal{SY-PI}(SY)$, AND CONSEQUENTLY, $\\mathcal{SY}(SY)$ ARE PSPACE IN COMPLEXITY.\n\n---\n**NOTE**    \nIt is later shown that if there were a Scotland yard instance such that each $f = show$, then it would be **PSPACE HARD** in complexity. Also if each $f = hide$, \nthen it would be **NP HARD** in complexity. These proofs are omitted due to the complexity of the math involved.\n\n---\n    ",heuristics:"\nNow that we've covered the complexity of Scotland Yard, let's go through a few strategies one would adopt after gaining a good amount of experience with the game. These strategeies are the best plan of action when trying to win the game either as Mr.X or as the detectives, but aren't proven to work for all cases and all layouts of the board.\n\n#### **The Detectives**\n\nIn order to capture Mr. X, the *detectives have to contain him to a portion of the board, and then keep  narrowing down on his position*. At the **start, the primary \nmotive of all detectives should be to move to highly connected stations**, as Mr. X will surface at the end of their second turn.\n\nOnce Mr. X has surfaced, *detectives should aim to close in as fast as possible, and try to keep Mr. X contained in 1/4 of the map. The underground \nand ferry routes should be kept covered so that the criminal cannot escape quickly*. The best way to contain him is to ensure that before each \nmove Mr. X has to surface, detectives are at highly connected stations.\n\nTo **capture Mr. X**, make sure *detectives are within one move of underground or river routes at all time, which will force Mr. X to make a double move*. The \n**earlier in the game Mr. X is forced to play a double move, the greater the advantage for detectives**, as he will have fewer options towards the end of the game.\n\nIn the previous section, *we showed how the game of imperfect information the detectives play is isomorphic to a game of perfect information by \nintroducing a set of all possible positions Mr. X could be at*. In real gameplay, it could be useful to note down the possible sets of stations Mr. X \ncould be at in order to maximize their coverage of that region. \n\n#### **Mr. X**\n\n*By making detectives believe Mr. X could be at a large number of possible locations, there are too many for them to now guard properly*. \n\nOn the turn where he must surface, *do so at a highly connected station, as in the next move, detectives will have a bigger set of possible stations Mr. X \ncould be at to worry about*. As undergrounds are limited in number, avoid them as much as possible, as it could give detectives a fairly clear idea of \nMr. X's position. On the other hand, as taxis can go anywhere, they are the most promiscuous mode of transport, increasing the number of locations he \ncould be hiding. However, they limit Mr. X to a portion of the board. \n\nWhen *Mr. X has to surface, at this round, detectives know exactly where his location his, so use a double move, taking \naway the advantage detectives had to narrow their containment circle*. If double move has been used up, surface at a location with more than one \nmode of transportation, which will increase the set of locations detectives have to worry about.\n\n**Playing with a lesser number of detectives will obviously be in Mr. X's favour.**\n\n## AI Simulation\n\nA simulation that plays the game will be that of perfect information, as it will keep track of the possible set of locations Mr. X \ncould be at while playing as the detectives. *In reality, as described as a strategy in the Heuristics part, people narrow down Mr. X's \nposition by attempting to keep track of Mr. X's locations as a set as well, but obviously not to the efficient extent a computer can.*\n\nThrough some **AI simulations that were run**, it was found that if both detectives and Mr. X employed the above strategies and played \nintelligently, *Mr. X won only about 30% of the time*.\n    ",solve1:"\nNow that we have analyzed the game and its complexity, let's move forward and try to begin to solve it by using a very famous algorithm called the **Monte Carlo Tree Search**.\n\nDue to limited information about the domain of the game and its probabilistic nature, applying generic ML algorithms like Minimax and alpha-beta pruning either \nturn out to be very complex or just not enough. \n\n#### **Monte Carlo Tree Search Overview**\n\nThe basic idea of the Monte Carlo Tree Search algorithm is that it further improves on basic recursive tree searching algorithms(BFS, DFS, etc.), by giving all \npaths a fair chance. It balances **Exploration** and **Exploitation.**\xa0\n\nExploration is when the other possible paths other than the current (perceived) optimal one in a search are periodically checked so \nas to not miss a better one to the required win condition. This expands on the breadth of the tree.\n\nExploitation is using the current optimal path and traversing deeper down from it. This expands on the length of the tree.\n\nA trade off of these two is what MCTS balances to give the best and most fair answer at the end. An MCTS iteration generally contains 4 steps:-\n\n1.  **Selection** - This is the first step in the iteration and is performed by traversing down the root by selecting nodes at every level using a max value returned after checking all nodes. The max value here is chosen by a formula , which takes into account factors like how many wins resulted when that node was visited , total number of visits to that node etc.. The formula is :-\n\n$$\nv_i = x_i + C*\\sqrt{\\frac{\\ln({n_p})}{n_i}}\n$$\n\nHere $v_i$ is the value from each node $i$ and the node chosen is the one that gives the maximum value of $v_i$ .\n\n$x_i$ here represents the average value of the node. This could have the form of $(number \\  of \\ wins / number \\ of \\ visits)$  , for example. This \nvalue is updated whenever , this node is revisited during a back propagation to the root (eg. number of visits increased by 1).\n\n$C$ is just a constant , and it controls the rate of exploration part. ($x_i$ represents the exploitation part as you would further want to \nexplore a node which has had many wins in few visits , so more the $x_i$ , more the exploitation)\n\n$n_p$ is the number of times the parent of the node $i$ has been visited.\n\n$n_i$ is the number of visits of the node $i$.\n\nNow here the part inside the square root indicates exploration. As number of visits to the node(denominator) increases , you \nwould want to explore this node less and less , and correspondingly this value will also decrease. However , the exploration \npossibilities increase logarithmic-ally ( $ln(n_p)$ ) with the visits to the parents (the more times you visit \nthe parent , the more curious you will get about exploring this node , makes sense right?)\n\nSo, using this formula , nodes are selected one by one as we traverse down the tree, until we reach a leaf node , from where we jump to the expansion step.\n    ",solve2:"\nHere the fractions inside the nodes represent the (number of wins / number of visits ). \nThe colour of the nodes represent whose turn it is (red player or blue player)\n\n2. **Expansion -** This step comprises of just adding a new node at the leaf node , reached by the selection step. This is the first step \ntowards expanding the tree. (and exploring more paths to a win)\n    ",solve3:"\nA new node is added after the leaf node from the selection step\n\n3. **Simulation -** In this step , random (or with some heuristics , which we will discuss later) moves are performed and the game is actually simulated \nbetween the two players. This is equivalent to adding one long path starting from the node added in the expansion step. This can be repeated several \ntimes, and huge number of moves can be simulated until a win or lose (or any end condition) is encountered , i.e another leaf node. From this leaf \nnode, now, back propagation starts.\n    ",solve4:"\nRandom moves are then played from this new node until an end condition\n\n4. **Back Propagation -** After determining the value of the last node of the simulation(win ,lose , draw , points etc.) , we recurs back till the root. \nDuring this , we increment number of visits of each node by 1. We can also update other things , like number of wins of each node , if the node resulted \nin a win for example. By this method , the average value of each node is updated.\n    ",solve5:"\nWe recurse back to the root and at each node, the number of wins and number of visits is incremented by one.\n\n#### **MCTS in Scotland Yard**\n\nNow that we know quite a bit about Monte Carlo Tree Search , let's see what do we need to setup before using it for Scotland Yard\n\n**A. Limiting Possible Locations**\n\nNow it's obvious that at every turn we can somehow narrow down the possibilities of where Mr. X could have gone by seeing the tickets he took, \nhis previous possible locations etc..\n\nSo let's formalize that!\n\nLet's take the following sub graph of Scotland Yard as an example..\n    ",solve6:"\nLet's say Mr. X revealed his position at 86. So our initial set of possible locations is just a singleton , which is `{86}`. Now let's say Mr. X \nplays a ticket but chooses a hidden card so we don't know whether he took the taxi or bus. So therefore, looking at the graph, the next set of \npossible locations becomes- `N {69 , 87 , 102 , 116 , 104 , 103}`. \n\nNow let's say the 5 Detectives move such that their positions now are - `D{53 , 55 , 103 , 127 , 87}`.\n\nNow assuming that the game didn't end there , we can remove `103` and `87` from the set N of locations of Mr. X as two detectives are on those \nlocations. So the final set before the next move becomes `{69 , 102 , 116 , 104}`. And after this seeing Mr. Xs set and the ticket he took we can construct the \nnext set. A formal way to write this algorithm could be : -\n    ",solve7:"\nHere $N$ represents the next set of possible Mr. X locations to be calculated. \n\n$M$ represents the previous set before this (This is initialized to the 29 possible locations of Mr. X when the game is started)\n\n$targets(p,t)$  is a function that gets us all the possible locations one can move to from a current location using a particular ticket.\n\n$D$ represents the current set of detective locations\n\nSo , using this before every iteration , we can narrow down the set for MCTS. But does this look right? Why would Mr. X try to go to 87 which \nis so close to a detective location (the detective literally lands on it). So we need a better way to bias some of the locations in the set \nthan the others. We look at that ahead.\n\n**B. Location Categorization**\n\nLet's try to categorize the locations in the set using $\\text{Minimum Distance}$ , which is the distance of the **nearest detective** to this location. \nBy distance here we mean number of moves ofcourse.\n\nLet's set up a model where we have 5 categories : -\n\n$\\text{Minimum Distance} = 1$\n\n$\\text{Minimum Distance} = 2$\n\n$\\text{Minimum Distance} = 3$\n\n$\\text{Minimum Distance} = 4$\n\n$\\text{Minimum Distance} \\geq 5$\n\nNow how do we give weights and bias to each of these and store them in a data structure which our beloved MCTS can use easily.\n\nLet's say we ran a lot of simulations of a game , and we noticed the following :-\n    ",solve8:"\nHere $a$ represents *number of times Mr. X himself was found to be in a location of the mentioned category*.\n\n$n$ represents *when a location in the set of possible locations of Mr. X was in the mentioned category* (includes the actual position)\n\nWhat we can do is now create a vector of length 5 (each field is a category) and give the value to each field as $\\frac a n$. Why does this \nmake sense? **Well obviously if percentage of Mr. Xs actual position out of all possible being in that category is more , that means that category is \nbest suited for the next consideration**. So now comes the question how to apply this bias. \n\nEach field in this vector is given a weighted probability based on its value ( $\\frac a n$ ) , and then the vector is chosen from randomly. This \nway obviously now the categories with the better value will get chosen with higher probability. \n\n**Notice** that we gave them *weighted probability and didn't simply select the one with the maximum valued*. We wanna make them smarter but not \ncompletely ignore the other possibilities. There is always a chance that Mr. X could have played a sneaky on us and deliberately gone to a risky location (He's Mr. X after all)\n\n**C. Heuristics During Simulation**\n\nDuring the *Simulation step of MCTS*, we cant simply simulate random moves , because that destroys the whole purpose. What we can do is give \nMr. X and the Detectives both some Heuristic way of playing so that both sides play kind of optimally and the simulation is a smart but fair one.\n\nHere's two possibilities : -\n\n1) **Detective \u2013 In a move he will try to minimize, the sum of distances to all possible locations of Mr. X.**\n\nWhat this **means is we will make the detective player biased towards going to such locations so that the squared sum of distances to all the \nlocations in Mr. X's set is minimized**\n\n2) **Mr. X - In a move , he will try to maximize distance from the nearest detective. If multiple such moves, he will choose the one that maximizes the \nsize of the possible moves set (to make it harder for detectives)**\n\nThis is pretty intuitive as well. *All this says is Mr. X will look at his nearest detective after the move and see if the distance \nto him is maximized*. If multiple such moves exist , he will move such that the next set of his possible locations that the detectives try \nto construct is very large (For eg. go to a junction with lot of taxi , bus and train routes or use a hidden/double ticket)\n\nThese are just what we thought were best. Maybe you could suggest some other smarter ones! (For eg. Using average distance to all detectives rather than minimum to nearest)\n\n**D. Coalition Reduction**\n\nThis is a small detail that tends to be overlooked. **Since the detectives play together as one player, the one detective that goes first, \nmakes it easy for the others after his move**. So, this could result in the *other detectives becoming \"lazy\" , and relying on just the first one or two*. \n\nTo avoid this , what we can model is this : -\n\nIf the first detective succeeds , a score 1 is returned. If the second succeeds , score $1 - r$ is returned , if 3rd $1- 2r$ and so on. \nHere $r$ is just a number between 0 and 1. If r is too small , the above problem prevails. Also if r is too large , the detectives \nmight get selfish and only try to maximize their score!\n    ",resource:'\n- **P. Nijssen and M. H. M. Winands, "Monte Carlo Tree Search for the Hide-and-Seek Game Scotland Yard," in IEEE Transactions** on Computational \nIntelligence and AI in Games, vol. 4, no. 4, pp. 282-294, Dec. 2012, doi: 10.1109/TCIAIG.2012.2210424.\n\n- **Sevenster, Merlijn. (2006). The complexity of Scotland Yard. Journal of Pharmacology and Experimental Therapeutics** - J PHARMACOL EXP THER.\n\n- Blogs on Monte Carlo Simulation\n    '},ie={fontFamily:"AudioWide",fontSize:"2rem"},oe={inlineMath:function(e){var t=e.value;return Object(s.jsx)(M.InlineMath,{math:t})},math:function(e){var t=e.value;return Object(s.jsx)(M.BlockMath,{math:t})}},re=Object(s.jsx)("div",{className:"my-4 py-2"}),le=function(){return Object(s.jsxs)(s.Fragment,{children:[Object(s.jsx)(E,{}),Object(s.jsxs)("div",{className:"d-flex-column align-items-end mt-3 p-0",style:{fontFamily:"Oswald",marginLeft:window.innerWidth>991?"5rem":"0.5rem"},children:[Object(s.jsx)("h1",{className:"text-center",style:{fontSize:"3rem",fontFamily:"AudioWide"},children:"SCOTLAND YARD"}),Object(s.jsx)("hr",{className:"mb-5"}),Object(s.jsxs)("div",{className:"container mb-5",style:{fontSize:"1.3rem"},children:[Object(s.jsx)("h2",{style:ie,children:"\ud83d\udcd6 INTRODUCTION"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.intro}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83d\udcdc RULES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.rule1}),Object(s.jsx)("div",{className:"text-center mb-4",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",style:{height:"40rem",width:"auto"},src:"/assets/ContentImages/ScotlandYard/1.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"Scotland Yard Map"})]})}),Object(s.jsx)(W.a,{source:ae.rule2}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83c\udfaf OBJECTIVE"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.obj}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83c\udfd7\ufe0f LAYING THE FOUNDATION"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.foundation,plugins:[B.a],renderers:oe}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83e\udd35 FORMALISATION"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.formal1,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/2.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.formal2,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/3.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.formal3,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/4.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.formal4,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/5.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.formal5,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/6.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.formal6,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/7.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.formal7,plugins:[B.a],renderers:oe}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83c\udf0c PSPACE"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.pspace,plugins:[B.a],renderers:oe}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83c\udfc3 HEURISTICS"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.heuristics,plugins:[B.a],renderers:oe}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83d\udee0\ufe0f SOLVING SCOTLAND YARD"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.solve1,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/8.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"Selection"})]})}),Object(s.jsx)(W.a,{source:ae.solve2,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/9.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"Expansion"})]})}),Object(s.jsx)(W.a,{source:ae.solve3,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/10.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"Simulation"})]})}),Object(s.jsx)(W.a,{source:ae.solve4,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/11.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"Back Propagation"})]})}),Object(s.jsx)(W.a,{source:ae.solve5,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsxs)("figure",{class:"figure",children:[Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/12.png",alt:""}),Object(s.jsx)("figcaption",{class:"figure-caption",children:"A sub-graph of Scotland Yard graph"})]})}),Object(s.jsx)(W.a,{source:ae.solve6,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/13.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.solve7,plugins:[B.a],renderers:oe}),Object(s.jsx)("div",{className:"text-center mb-4 mt-2",children:Object(s.jsx)("figure",{class:"figure",children:Object(s.jsx)("img",{className:"img-fluid figure-img  mx-auto d-block",src:"/assets/ContentImages/ScotlandYard/14.png",alt:""})})}),Object(s.jsx)(W.a,{source:ae.solve8,plugins:[B.a],renderers:oe}),re,Object(s.jsx)("h2",{style:ie,children:"\ud83d\udcdd REFERENCES"}),Object(s.jsx)("hr",{className:"mb-4"}),Object(s.jsx)(W.a,{source:ae.resource}),Object(s.jsx)("hr",{className:"mb-1"}),Object(s.jsx)("h1",{className:"display-1 text-center",children:"\ud83d\udd75\ufe0f\u200d\u2642\ufe0f"})]})]})]})},ce=Object(c.f)((function(e){return"/"===e.location.pathname?null:Object(s.jsx)(b.a.nav,{className:"navbar navbar-light d-block d-lg-none",style:{backgroundColor:"#000000"},initial:{y:-100},animate:{y:0},transition:{duration:1},children:Object(s.jsx)(l.b,{className:"navbar-brand mt-1 ml-1",to:"/",children:Object(s.jsx)(O.a,{icon:N.a,style:{fontSize:"2rem",color:"#CCFF00"}})})})}));var he=function(){return Object(s.jsxs)(l.a,{children:[Object(s.jsx)(ce,{}),Object(s.jsx)(T,{}),Object(s.jsxs)(c.c,{children:[Object(s.jsx)(c.a,{exact:!0,path:"/",component:$}),Object(s.jsx)(c.a,{exact:!0,path:"/bullsandcows",component:Y}),Object(s.jsx)(c.a,{exact:!0,path:"/chopsticks",component:R}),Object(s.jsx)(c.a,{exact:!0,path:"/connectfour",component:J}),Object(s.jsx)(c.a,{exact:!0,path:"/guesswho",component:se}),Object(s.jsx)(c.a,{exact:!0,path:"/scotlandyard",component:le})]})]})};n(170);r.a.render(Object(s.jsx)(i.a.StrictMode,{children:Object(s.jsx)(he,{})}),document.getElementById("root"))},86:function(e,t,n){}},[[171,1,2]]]);
//# sourceMappingURL=main.f6d059e3.chunk.js.map